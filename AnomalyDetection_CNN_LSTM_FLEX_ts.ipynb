{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Deep Model with Flex  for Anomaly Detection with Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we do all the imports needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 01:03:09.144388: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 01:03:09.256866: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-11 01:03:09.260932: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-12-11 01:03:09.260949: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-12-11 01:03:09.741948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-11 01:03:09.742016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-11 01:03:09.742020: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from flexanomalies.models import DeepCNN_LSTM\n",
    "from flexanomalies.utils.load_data import load_and_split_csv, federate_data\n",
    "from flexanomalies.pool.decorators_autoencoder import build_server_model_ae, copy_model_to_clients_ae,train_ae, aggregate_ae, set_aggregated_weights_ae, weights_collector_ae\n",
    "from flexanomalies.utils.save_results import save_experiments_results\n",
    "from flex.pool import FlexPool\n",
    "from flexanomalies.utils.metrics import *\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"epochs\": 5,\n",
    "    \"input_dim\":41,\n",
    "    \"batch_size\": 32,\n",
    "    \"filters_cnn\": [32,32],\n",
    "    \"units_lstm\": [32,32],\n",
    "    \"kernel_size\": [5,5],\n",
    "    \"hidden_act\": [\"relu\",\"relu\"],\n",
    "    \"w_size\":30,\n",
    "    \"n_pred\": 1,\n",
    "    \"contamination\": 0.1\n",
    "}\n",
    "\n",
    "file_path = \"../flex-anomalies/flexanomalies/datasets/data/corrected.gz\"\n",
    "split_test = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, l_train, l_test = load_and_split_csv(file_path,model_params[\"input_dim\"],split_test)\n",
    "for i in range(len(l_train)):\n",
    "    if l_train[i] == \"normal.\":\n",
    "        l_train[i] = 0\n",
    "    else:\n",
    "         l_train[i] = 1   \n",
    "\n",
    "for i in range(len(l_test)):\n",
    "    if l_test[i] == \"normal.\":\n",
    "        l_test[i] = 0\n",
    "    else:\n",
    "         l_test[i] = 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows (w_size,n_pred):   # Number of predictions into the future\n",
    "    X_train_windows = []\n",
    "    y_train_windows = []\n",
    "    X_test_windows = []\n",
    "    y_test_windows = []  \n",
    "    \n",
    "   \n",
    "    for i in range(w_size, len(X_train) - n_pred +1,n_pred):\n",
    "        X_train_windows.append(X_train[i - w_size:i, :])                        \n",
    "        \n",
    "        y_train_windows.append(X_train[i:i + n_pred, :])  \n",
    "\n",
    "       # y_train_windows.append(y_train[i:i + n_pred].reshape(-1,1))        \n",
    "        \n",
    "\n",
    "    #Test    \n",
    "    for i in range(w_size, len(X_test) - n_pred +1,n_pred):\n",
    "        X_test_windows.append(X_test[i - w_size:i, :])                        \n",
    "        \n",
    "        y_test_windows.append(X_test[i:i + n_pred, :])  \n",
    "\n",
    "        #y_test_windows.append(y_test[i:i + n_pred].reshape(-1,1))   \n",
    "       \n",
    "    print('X_train shape == {}.'.format(np.array(X_train_windows).shape))\n",
    "    \n",
    "    print('y_train shape == {}.'.format(np.array(y_train_windows).shape))\n",
    "\n",
    "    print('X_test shape == {}.'.format(np.array(X_test_windows).shape))\n",
    "   \n",
    "    print('y_test shape == {}.'.format(np.array(y_test_windows).shape))\n",
    "   \n",
    "\n",
    "    return np.array(X_train_windows, np.array(y_train_windows), np.array(X_test_windows), np.array(y_test_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape == (21768, 30, 41).\n",
      "y_train shape == (21768, 10, 41).\n",
      "X_test shape == (9327, 30, 41).\n",
      "y_test shape == (9327, 10, 41).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train_windows, y_train_windows, X_test_windows,y_test_windows  \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m, in \u001b[0;36mcreate_windows\u001b[0;34m(w_size, n_pred)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test shape == \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39marray(X_test_windows)\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test shape == \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39marray(y_test_windows)\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mX_train_windows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(\u001b[38;5;28mfloat\u001b[39m)), np\u001b[38;5;241m.\u001b[39marray(y_train_windows), np\u001b[38;5;241m.\u001b[39marray(X_test_windows), np\u001b[38;5;241m.\u001b[39marray(y_test_windows)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "X_train_windows, y_train_windows, X_test_windows,y_test_windows  = create_windows(30,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 01:03:13.175229: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-12-11 01:03:13.175251: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-12-11 01:03:13.175271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (beatriz-IdeaPad-3-15ITL6): /proc/driver/nvidia/version does not exist\n",
      "2023-12-11 01:03:13.175531: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu 32 5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 26, 32)            6592      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 13, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 9, 32)             5152      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 4, 32)             8320      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 4, 32)             8320      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 41)                5289      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,673\n",
      "Trainable params: 33,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = DeepCNN_LSTM(**model_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dataset = federate_data(5, X_train_windows, y_train_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(X_data=len:4353\n",
       "is_generator:False\n",
       "iterable:[[[0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
       "  [0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  ...\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
       "\n",
       " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
       "  [0 'tcp' 'private' ... 1.0 0.0 0.0]\n",
       "  ...\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
       "\n",
       " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'udp' 'domain_u' ... 0.0 0.0 0.0]\n",
       "  ...\n",
       "  [0 'udp' 'private' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  ...\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [4 'tcp' 'pop_3' ... 0.0 0.0 0.0]]\n",
       "\n",
       " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'private' ... 1.0 0.0 0.0]\n",
       "  ...\n",
       "  [1 'tcp' 'smtp' ... 0.0 0.03 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'http' ... 0.0 0.0 0.0]]\n",
       "\n",
       " [[0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  ...\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]]\n",
       "iterable_indexes:[   0    1    2 ... 4350 4351 4352]\n",
       "storage:{}, y_data=len:4353\n",
       "is_generator:False\n",
       "iterable:[[[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
       "  ...\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
       "\n",
       " [[0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'smtp' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
       "  ...\n",
       "  [0 'udp' 'private' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
       "\n",
       " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  ...\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'udp' 'private' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'private' ... 0.0 1.0 1.0]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'udp' 'private' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  ...\n",
       "  [1 'tcp' 'smtp' ... 0.0 0.03 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'http' ... 0.0 0.0 0.0]]\n",
       "\n",
       " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [1 'tcp' 'smtp' ... 0.0 0.03 0.0]\n",
       "  [0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
       "  ...\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
       "\n",
       " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  ...\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
       "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
       "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]]\n",
       "iterable_indexes:[   0    1    2 ... 4350 4351 4352]\n",
       "storage:{})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = FlexPool.client_server_pool(\n",
    "        fed_dataset=flex_dataset,\n",
    "        server_id=\"cnn_lstm_server\",\n",
    "        init_func=build_server_model_ae,\n",
    "        model=model,\n",
    "    )\n",
    "pool.clients._data[\"client1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running round: 0\n",
      "\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-11 01:03:14         4242\n",
      "variables.h5                                   2023-12-11 01:03:14       162904\n",
      "metadata.json                                  2023-12-11 01:03:14           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-11 01:03:14         4242\n",
      "variables.h5                                   2023-12-11 01:03:14       162904\n",
      "metadata.json                                  2023-12-11 01:03:14           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-11 01:03:14         4242\n",
      "variables.h5                                   2023-12-11 01:03:14       162904\n",
      "metadata.json                                  2023-12-11 01:03:14           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-11 01:03:14         4242\n",
      "variables.h5                                   2023-12-11 01:03:14       162904\n",
      "metadata.json                                  2023-12-11 01:03:14           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-11 01:03:14         4242\n",
      "variables.h5                                   2023-12-11 01:03:14       162904\n",
      "metadata.json                                  2023-12-11 01:03:14           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-11 01:03:14         4242\n",
      "variables.h5                                   2023-12-11 01:03:14       162904\n",
      "metadata.json                                  2023-12-11 01:03:14           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-11 01:03:15         4242\n",
      "variables.h5                                   2023-12-11 01:03:15       162904\n",
      "metadata.json                                  2023-12-11 01:03:15           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-11 01:03:14         4242\n",
      "variables.h5                                   2023-12-11 01:03:14       162904\n",
      "metadata.json                                  2023-12-11 01:03:14           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-11 01:03:15         4242\n",
      "variables.h5                                   2023-12-11 01:03:15       162904\n",
      "metadata.json                                  2023-12-11 01:03:15           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-11 01:03:14         4242\n",
      "variables.h5                                   2023-12-11 01:03:14       162904\n",
      "metadata.json                                  2023-12-11 01:03:14           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Training model at client.\n",
      "Dataset(X_data=len:4353\n",
      "is_generator:False\n",
      "iterable:[[[0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
      "  [0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  ...\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
      "\n",
      " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
      "  [0 'tcp' 'private' ... 1.0 0.0 0.0]\n",
      "  ...\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
      "\n",
      " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'udp' 'domain_u' ... 0.0 0.0 0.0]\n",
      "  ...\n",
      "  [0 'udp' 'private' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  ...\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [4 'tcp' 'pop_3' ... 0.0 0.0 0.0]]\n",
      "\n",
      " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'private' ... 1.0 0.0 0.0]\n",
      "  ...\n",
      "  [1 'tcp' 'smtp' ... 0.0 0.03 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'http' ... 0.0 0.0 0.0]]\n",
      "\n",
      " [[0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  ...\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]]\n",
      "iterable_indexes:[   0    1    2 ... 4350 4351 4352]\n",
      "storage:{}, y_data=len:4353\n",
      "is_generator:False\n",
      "iterable:[[[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
      "  ...\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
      "\n",
      " [[0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'smtp' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
      "  ...\n",
      "  [0 'udp' 'private' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
      "\n",
      " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  ...\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'udp' 'private' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'private' ... 0.0 1.0 1.0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'udp' 'private' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  ...\n",
      "  [1 'tcp' 'smtp' ... 0.0 0.03 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'http' ... 0.0 0.0 0.0]]\n",
      "\n",
      " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [1 'tcp' 'smtp' ... 0.0 0.03 0.0]\n",
      "  [0 'tcp' 'http' ... 0.0 0.0 0.0]\n",
      "  ...\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]\n",
      "\n",
      " [[0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  ...\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]\n",
      "  [0 'tcp' 'private' ... 0.0 1.0 1.0]\n",
      "  [0 'icmp' 'ecr_i' ... 0.0 0.0 0.0]]]\n",
      "iterable_indexes:[   0    1    2 ... 4350 4351 4352]\n",
      "storage:{})\n",
      "(4353, 30, 41)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning round: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m pool\u001b[38;5;241m.\u001b[39mservers\u001b[38;5;241m.\u001b[39mmap(copy_model_to_clients_ae, pool\u001b[38;5;241m.\u001b[39mclients)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ae\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m pool\u001b[38;5;241m.\u001b[39maggregators\u001b[38;5;241m.\u001b[39mmap(weights_collector_ae, pool\u001b[38;5;241m.\u001b[39mclients)\n\u001b[1;32m      6\u001b[0m pool\u001b[38;5;241m.\u001b[39maggregators\u001b[38;5;241m.\u001b[39mmap(aggregate_ae)\n",
      "File \u001b[0;32m/data/Beatriz/Doctorado GR/FLEXible-main/flex/pool/pool.py:116\u001b[0m, in \u001b[0;36mFlexPool.map\u001b[0;34m(self, func, dst_pool, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Method used to send messages from one pool to another. The pool using\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39mthis method is the source pool, and it will send a message, apply a function,\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39mto the destination pool. If no destination pool is provided, then the function is applied\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m    length of the returned values equals the number of actors in the source pool.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m dst_pool \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     res \u001b[39m=\u001b[39m [\n\u001b[1;32m    117\u001b[0m         func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_models\u001b[39m.\u001b[39mget(i), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mget(i), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actors\n\u001b[1;32m    119\u001b[0m     ]\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m FlexPool\u001b[39m.\u001b[39mcheck_compatibility(\u001b[39mself\u001b[39m, dst_pool):\n\u001b[1;32m    121\u001b[0m     res \u001b[39m=\u001b[39m [\n\u001b[1;32m    122\u001b[0m         func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_models\u001b[39m.\u001b[39mget(i), dst_pool\u001b[39m.\u001b[39m_models, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    123\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actors\n\u001b[1;32m    124\u001b[0m     ]\n",
      "File \u001b[0;32m/data/Beatriz/Doctorado GR/FLEXible-main/flex/pool/pool.py:117\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Method used to send messages from one pool to another. The pool using\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39mthis method is the source pool, and it will send a message, apply a function,\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39mto the destination pool. If no destination pool is provided, then the function is applied\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m    length of the returned values equals the number of actors in the source pool.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m dst_pool \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     res \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 117\u001b[0m         func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_models\u001b[39m.\u001b[39;49mget(i), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data\u001b[39m.\u001b[39;49mget(i), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    118\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actors\n\u001b[1;32m    119\u001b[0m     ]\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m FlexPool\u001b[39m.\u001b[39mcheck_compatibility(\u001b[39mself\u001b[39m, dst_pool):\n\u001b[1;32m    121\u001b[0m     res \u001b[39m=\u001b[39m [\n\u001b[1;32m    122\u001b[0m         func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_models\u001b[39m.\u001b[39mget(i), dst_pool\u001b[39m.\u001b[39m_models, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    123\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actors\n\u001b[1;32m    124\u001b[0m     ]\n",
      "File \u001b[0;32m/data/Beatriz/Doctorado GR/flex-anomalies/flexanomalies/pool/decorators_autoencoder.py:46\u001b[0m, in \u001b[0;36mtrain_ae\u001b[0;34m(client_model, client_data)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(client_data)\n\u001b[1;32m     45\u001b[0m \u001b[39mprint\u001b[39m(X_data\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 46\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_data, y_data)\n",
      "File \u001b[0;32m/data/Beatriz/Doctorado GR/flex-anomalies/flexanomalies/models/cnn_lstm.py:159\u001b[0m, in \u001b[0;36mDeepCNN_LSTM.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39mX : numpy array of shape (samples, features)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39my:  Ignored in unsupervised methods\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m#np.random.shuffle(Xscaler)\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    160\u001b[0m     X,\n\u001b[1;32m    161\u001b[0m     y,\n\u001b[1;32m    162\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs,\n\u001b[1;32m    163\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[1;32m    164\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    165\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidation_size,\n\u001b[1;32m    166\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    167\u001b[0m )\u001b[39m.\u001b[39mhistory\n",
      "File \u001b[0;32m/data/Beatriz/Doctorado GR/flex-anomalies/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/data/Beatriz/Doctorado GR/flex-anomalies/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"\\nRunning round: {i}\\n\")\n",
    "    pool.servers.map(copy_model_to_clients_ae, pool.clients)\n",
    "    pool.clients.map(train_ae)\n",
    "    pool.aggregators.map(weights_collector_ae, pool.clients)\n",
    "    pool.aggregators.map(aggregate_ae)\n",
    "    pool.aggregators.map(set_aggregated_weights_ae, pool.servers)\n",
    "output_model = pool.servers._models[\"cnn_lstm_server\"][\"model\"]\n",
    "output_model.evaluate(X_test_windows,l_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model.result_metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_experiments_results(\n",
    "    'cnn_lstm',\n",
    "    output_model,\n",
    "    'test_cnn_lstm_notebook',\n",
    "    model_params,\n",
    "    'shuttle.mat',\n",
    "    5,\n",
    "    3,\n",
    "    0.3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1bb7960fd30cfaed40cb92889ad99bb2687045b6865895d20dad709adf6b60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
