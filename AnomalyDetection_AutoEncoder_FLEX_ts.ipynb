{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.models import AutoEncoder\n",
    "from flexanomalies.utils.load_data import split_data, federate_data\n",
    "from flexanomalies.datasets.preprocessing_utils import (\n",
    "    create_windows,\n",
    "    encode_and_bind,\n",
    "    scaling,\n",
    "    impute_lost_values,\n",
    ")\n",
    "from flexanomalies.utils.metrics import print_metrics\n",
    "from flexanomalies.utils.process_scores import (\n",
    "    process_scores_with_percentile,\n",
    "    process_scores_with_threshold,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from flexanomalies.pool.primitives_deepmodel import (\n",
    "    build_server_model_ae,\n",
    "    copy_model_to_clients_ae,\n",
    "    train_ae,\n",
    "    set_aggregated_weights_ae,\n",
    "    weights_collector_ae,\n",
    "    evaluate_global_model,\n",
    "    evaluate_global_model_clients,\n",
    "    threshold_collector_ae,\n",
    ")\n",
    "from flexanomalies.pool.aggregators_favg import aggregate_ae\n",
    "from flexanomalies.utils.save_results import save_experiments_results\n",
    "from flex.pool import FlexPool\n",
    "from flexanomalies.utils.metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../flex-anomalies/flexanomalies/datasets/data/corrected.gz\"\n",
    "split_test = 0.3\n",
    "\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# process labels\n",
    "df.loc[df[41] != \"normal.\", 41] = 1\n",
    "df.loc[df[41] == \"normal.\", 41] = 0\n",
    "labels = df[41]\n",
    "df = df.drop([41], axis=1)\n",
    "\n",
    "features_to_encode = [1, 2, 3]\n",
    "df = df.drop(features_to_encode, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"epochs\": 100,\n",
    "    \"input_dim\": df.shape[1],\n",
    "    \"batch_size\": 32,\n",
    "    \"neurons\": [16, 8, 16],\n",
    "    \"hidden_act\": [\"relu\", \"relu\", \"relu\"],\n",
    "    \"preprocess\":False,\n",
    "    \"w_size\": 30,\n",
    "    \"n_pred\": 10,\n",
    "    \"contamination\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaling(np.array(df.iloc[:, :].astype(float)))\n",
    "y = np.array(labels)\n",
    "X_train, X_test, l_train, l_test = split_data(X, y, split_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(w_size, n_pred, X_train, X_test, l_train, l_test):\n",
    "    X_train_windows = []\n",
    "    y_train_windows = []\n",
    "    X_test_windows = []\n",
    "    y_test_windows = []\n",
    "\n",
    "    for i in range(0, len(X_train), n_pred):\n",
    "        temp_xtrain = X_train[i : w_size + i, :]\n",
    "        temp_ytrain = l_train[i : w_size + i]\n",
    "        if len(temp_xtrain) < w_size or len(temp_ytrain) < n_pred:\n",
    "            break\n",
    "        X_train_windows.append(temp_xtrain)\n",
    "\n",
    "        y_train_windows.append(temp_ytrain)\n",
    "\n",
    "    for i in range(0, len(X_test), n_pred):\n",
    "\n",
    "        temp_xtest = X_test[i : w_size + i, :]\n",
    "        temp_ytest = l_test[i : w_size + i]\n",
    "        if len(temp_xtest) < w_size or len(temp_ytest) < n_pred:\n",
    "            break\n",
    "\n",
    "        X_test_windows.append(temp_xtest)\n",
    "\n",
    "        y_test_windows.append(temp_ytest)\n",
    "\n",
    "    return (\n",
    "        np.array(X_train_windows),\n",
    "        np.array(y_train_windows),\n",
    "        np.array(X_test_windows),\n",
    "        np.array(y_test_windows),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape == (21770, 30, 38).\n",
      "y_train shape == (21770, 30).\n",
      "X_test shape == (9328, 30, 38).\n",
      "y_test shape == (9328, 30).\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    X_train_windows,\n",
    "    y_train_windows,\n",
    "    X_test_windows,\n",
    "    y_test_windows,\n",
    "    \n",
    ") = create_windows(model_params[\"w_size\"], model_params[\"n_pred\"], X_train, X_test,l_train, l_test)\n",
    "\n",
    "print(\"X_train shape == {}.\".format(np.array(X_train_windows).shape))\n",
    "print(\"y_train shape == {}.\".format(np.array(y_train_windows).shape))\n",
    "print(\"X_test shape == {}.\".format(np.array(X_test_windows).shape))\n",
    "print(\"y_test shape == {}.\".format(np.array(y_test_windows).shape))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(**model_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dataset = federate_data(5, X_train_windows,y_train_windows)\n",
    "pool = FlexPool.client_server_pool(\n",
    "    fed_dataset=flex_dataset,\n",
    "    server_id=\"autoencoder_server\",\n",
    "    init_func=build_server_model_ae,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running round: 0\n",
      "\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-10 17:15:12         2246\n",
      "variables.h5                                   2024-01-10 17:15:12        22544\n",
      "metadata.json                                  2024-01-10 17:15:12           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-10 17:15:12         2246\n",
      "variables.h5                                   2024-01-10 17:15:12        22544\n",
      "metadata.json                                  2024-01-10 17:15:12           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-10 17:15:12         2246\n",
      "variables.h5                                   2024-01-10 17:15:12        22544\n",
      "metadata.json                                  2024-01-10 17:15:12           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-10 17:15:12         2246\n",
      "variables.h5                                   2024-01-10 17:15:12        22544\n",
      "metadata.json                                  2024-01-10 17:15:12           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-10 17:15:13         2246\n",
      "variables.h5                                   2024-01-10 17:15:13        22544\n",
      "metadata.json                                  2024-01-10 17:15:13           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-10 17:15:12         2246\n",
      "variables.h5                                   2024-01-10 17:15:12        22544\n",
      "metadata.json                                  2024-01-10 17:15:12           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-10 17:15:13         2246\n",
      "variables.h5                                   2024-01-10 17:15:13        22544\n",
      "metadata.json                                  2024-01-10 17:15:13           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-10 17:15:12         2246\n",
      "variables.h5                                   2024-01-10 17:15:12        22544\n",
      "metadata.json                                  2024-01-10 17:15:12           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-10 17:15:13         2246\n",
      "variables.h5                                   2024-01-10 17:15:13        22544\n",
      "metadata.json                                  2024-01-10 17:15:13           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-10 17:15:12         2246\n",
      "variables.h5                                   2024-01-10 17:15:12        22544\n",
      "metadata.json                                  2024-01-10 17:15:12           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Training model at client.\n",
      "Epoch 1/100\n",
      "109/109 [==============================] - 2s 8ms/step - loss: 0.9949 - val_loss: 0.9058\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.6773 - val_loss: 0.6023\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.5242 - val_loss: 0.5274\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4670 - val_loss: 0.4691\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4103 - val_loss: 0.4062\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3558 - val_loss: 0.3592\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.3112 - val_loss: 0.3190\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.2683 - val_loss: 0.2884\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.2372 - val_loss: 0.2671\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.2120 - val_loss: 0.2551\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1933 - val_loss: 0.2398\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1801 - val_loss: 0.2316\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1700 - val_loss: 0.2243\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1625 - val_loss: 0.2207\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1566 - val_loss: 0.2157\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1525 - val_loss: 0.2118\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1481 - val_loss: 0.2094\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.1449 - val_loss: 0.2044\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1417 - val_loss: 0.2028\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1394 - val_loss: 0.1993\n",
      "Epoch 21/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1373 - val_loss: 0.1984\n",
      "Epoch 22/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1355 - val_loss: 0.1960\n",
      "Epoch 23/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1338 - val_loss: 0.1930\n",
      "Epoch 24/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1320 - val_loss: 0.1924\n",
      "Epoch 25/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1308 - val_loss: 0.1907\n",
      "Epoch 26/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1295 - val_loss: 0.1900\n",
      "Epoch 27/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1288 - val_loss: 0.1883\n",
      "Epoch 28/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1278 - val_loss: 0.1870\n",
      "Epoch 29/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1270 - val_loss: 0.1862\n",
      "Epoch 30/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1258 - val_loss: 0.1853\n",
      "Epoch 31/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1252 - val_loss: 0.1853\n",
      "Epoch 32/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1245 - val_loss: 0.1847\n",
      "Epoch 33/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1244 - val_loss: 0.1830\n",
      "Epoch 34/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1238 - val_loss: 0.1832\n",
      "Epoch 35/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1235 - val_loss: 0.1836\n",
      "Epoch 36/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1233 - val_loss: 0.1828\n",
      "Epoch 37/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1222 - val_loss: 0.1825\n",
      "Epoch 38/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1219 - val_loss: 0.1814\n",
      "Epoch 39/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1212 - val_loss: 0.1801\n",
      "Epoch 40/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1205 - val_loss: 0.1801\n",
      "Epoch 41/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1201 - val_loss: 0.1791\n",
      "Epoch 42/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1196 - val_loss: 0.1794\n",
      "Epoch 43/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1196 - val_loss: 0.1801\n",
      "Epoch 44/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1191 - val_loss: 0.1782\n",
      "Epoch 45/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1188 - val_loss: 0.1791\n",
      "Epoch 46/100\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.1182 - val_loss: 0.1780\n",
      "Epoch 47/100\n",
      "109/109 [==============================] - 1s 9ms/step - loss: 0.1178 - val_loss: 0.1768\n",
      "Epoch 48/100\n",
      "109/109 [==============================] - 1s 8ms/step - loss: 0.1175 - val_loss: 0.1762\n",
      "Epoch 49/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1176 - val_loss: 0.1766\n",
      "Epoch 50/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1169 - val_loss: 0.1771\n",
      "Epoch 51/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1160 - val_loss: 0.1746\n",
      "Epoch 52/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1152 - val_loss: 0.1748\n",
      "Epoch 53/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1153 - val_loss: 0.1749\n",
      "Epoch 54/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1143 - val_loss: 0.1738\n",
      "Epoch 55/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1140 - val_loss: 0.1733\n",
      "Epoch 56/100\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.1133 - val_loss: 0.1731\n",
      "Epoch 57/100\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.1129 - val_loss: 0.1722\n",
      "Epoch 58/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1122 - val_loss: 0.1722\n",
      "Epoch 58: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/100\n",
      "109/109 [==============================] - 2s 8ms/step - loss: 0.9034 - val_loss: 0.8511\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.5774 - val_loss: 0.5882\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.4616 - val_loss: 0.5366\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.4164 - val_loss: 0.4979\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.3719 - val_loss: 0.4617\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.3272 - val_loss: 0.4148\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.2863 - val_loss: 0.3747\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.2507 - val_loss: 0.3291\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.2229 - val_loss: 0.2870\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1950 - val_loss: 0.2457\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1700 - val_loss: 0.2104\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.1497 - val_loss: 0.1883\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1353 - val_loss: 0.1727\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1261 - val_loss: 0.1636\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1197 - val_loss: 0.1601\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.1156 - val_loss: 0.1565\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1108 - val_loss: 0.1542\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.1097 - val_loss: 0.1506\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.1045 - val_loss: 0.1481\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1020 - val_loss: 0.1521\n",
      "Epoch 21/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1007 - val_loss: 0.1429\n",
      "Epoch 22/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0967 - val_loss: 0.1414\n",
      "Epoch 23/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0942 - val_loss: 0.1387\n",
      "Epoch 24/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0922 - val_loss: 0.1375\n",
      "Epoch 25/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0901 - val_loss: 0.1353\n",
      "Epoch 26/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0891 - val_loss: 0.1377\n",
      "Epoch 27/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0876 - val_loss: 0.1327\n",
      "Epoch 28/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0849 - val_loss: 0.1317\n",
      "Epoch 29/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0834 - val_loss: 0.1292\n",
      "Epoch 30/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0823 - val_loss: 0.1282\n",
      "Epoch 31/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0805 - val_loss: 0.1262\n",
      "Epoch 32/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0795 - val_loss: 0.1265\n",
      "Epoch 33/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0782 - val_loss: 0.1230\n",
      "Epoch 34/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0777 - val_loss: 0.1251\n",
      "Epoch 35/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0765 - val_loss: 0.1214\n",
      "Epoch 36/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0744 - val_loss: 0.1202\n",
      "Epoch 37/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0733 - val_loss: 0.1181\n",
      "Epoch 38/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0717 - val_loss: 0.1172\n",
      "Epoch 39/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0707 - val_loss: 0.1160\n",
      "Epoch 40/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0711 - val_loss: 0.1167\n",
      "Epoch 41/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0713 - val_loss: 0.1183\n",
      "Epoch 42/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0705 - val_loss: 0.1166\n",
      "Epoch 43/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0682 - val_loss: 0.1127\n",
      "Epoch 44/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0668 - val_loss: 0.1105\n",
      "Epoch 45/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0655 - val_loss: 0.1114\n",
      "Epoch 46/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0648 - val_loss: 0.1086\n",
      "Epoch 47/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0648 - val_loss: 0.1087\n",
      "Epoch 48/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0639 - val_loss: 0.1079\n",
      "Epoch 49/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0631 - val_loss: 0.1077\n",
      "Epoch 50/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0630 - val_loss: 0.1067\n",
      "Epoch 51/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0632 - val_loss: 0.1060\n",
      "Epoch 52/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0644 - val_loss: 0.1162\n",
      "Epoch 53/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0663 - val_loss: 0.1064\n",
      "Epoch 54/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0620 - val_loss: 0.1072\n",
      "Epoch 55/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0619 - val_loss: 0.1044\n",
      "Epoch 56/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0606 - val_loss: 0.1037\n",
      "Epoch 57/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0602 - val_loss: 0.1030\n",
      "Epoch 58/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0597 - val_loss: 0.1030\n",
      "Epoch 59/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0595 - val_loss: 0.1030\n",
      "Epoch 59: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/100\n",
      "109/109 [==============================] - 3s 8ms/step - loss: 0.8102 - val_loss: 0.7545\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4856 - val_loss: 0.4750\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3656 - val_loss: 0.4154\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3220 - val_loss: 0.3676\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.2849 - val_loss: 0.3204\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.2512 - val_loss: 0.2764\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.2183 - val_loss: 0.2307\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1907 - val_loss: 0.1966\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1689 - val_loss: 0.1764\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1545 - val_loss: 0.1631\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1428 - val_loss: 0.1544\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1332 - val_loss: 0.1445\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1252 - val_loss: 0.1381\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1187 - val_loss: 0.1345\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1144 - val_loss: 0.1299\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1090 - val_loss: 0.1258\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1065 - val_loss: 0.1256\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1052 - val_loss: 0.1242\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1007 - val_loss: 0.1170\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1116\n",
      "Epoch 21/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0917 - val_loss: 0.1060\n",
      "Epoch 22/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0881 - val_loss: 0.1017\n",
      "Epoch 23/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0852 - val_loss: 0.0975\n",
      "Epoch 24/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0830 - val_loss: 0.0957\n",
      "Epoch 25/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0806 - val_loss: 0.0910\n",
      "Epoch 26/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0786 - val_loss: 0.0949\n",
      "Epoch 27/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0783 - val_loss: 0.0932\n",
      "Epoch 28/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0755 - val_loss: 0.0839\n",
      "Epoch 29/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0725 - val_loss: 0.0816\n",
      "Epoch 30/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0710 - val_loss: 0.0798\n",
      "Epoch 31/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0698 - val_loss: 0.0784\n",
      "Epoch 32/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0687 - val_loss: 0.0780\n",
      "Epoch 33/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0677 - val_loss: 0.0763\n",
      "Epoch 34/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0665 - val_loss: 0.0771\n",
      "Epoch 35/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0666 - val_loss: 0.0754\n",
      "Epoch 36/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0667 - val_loss: 0.0814\n",
      "Epoch 37/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0671 - val_loss: 0.0728\n",
      "Epoch 38/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0635 - val_loss: 0.0716\n",
      "Epoch 39/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0634 - val_loss: 0.0721\n",
      "Epoch 40/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0624 - val_loss: 0.0721\n",
      "Epoch 41/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0623 - val_loss: 0.0702\n",
      "Epoch 42/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0610 - val_loss: 0.0692\n",
      "Epoch 43/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0601 - val_loss: 0.0688\n",
      "Epoch 44/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0599 - val_loss: 0.0684\n",
      "Epoch 45/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0593 - val_loss: 0.0680\n",
      "Epoch 46/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0590 - val_loss: 0.0668\n",
      "Epoch 47/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0577 - val_loss: 0.0656\n",
      "Epoch 48/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0574 - val_loss: 0.0649\n",
      "Epoch 49/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0572 - val_loss: 0.0646\n",
      "Epoch 50/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0565 - val_loss: 0.0642\n",
      "Epoch 51/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0556 - val_loss: 0.0643\n",
      "Epoch 52/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0556 - val_loss: 0.0658\n",
      "Epoch 53/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0571 - val_loss: 0.0664\n",
      "Epoch 54/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0554 - val_loss: 0.0627\n",
      "Epoch 55/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0541 - val_loss: 0.0621\n",
      "Epoch 56/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0538 - val_loss: 0.0621\n",
      "Epoch 56: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/100\n",
      "109/109 [==============================] - 2s 8ms/step - loss: 0.8462 - val_loss: 0.7593\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.5420 - val_loss: 0.4986\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.4174 - val_loss: 0.4307\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.3647 - val_loss: 0.3721\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3138 - val_loss: 0.3163\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.2711 - val_loss: 0.2653\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.2346 - val_loss: 0.2270\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.2089 - val_loss: 0.2014\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1903 - val_loss: 0.1826\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1778 - val_loss: 0.1723\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1704 - val_loss: 0.1616\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.1633 - val_loss: 0.1573\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.1577 - val_loss: 0.1494\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1529 - val_loss: 0.1447\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1502 - val_loss: 0.1419\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1459 - val_loss: 0.1384\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1425 - val_loss: 0.1351\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1400 - val_loss: 0.1308\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1373 - val_loss: 0.1298\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1346 - val_loss: 0.1263\n",
      "Epoch 21/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1325 - val_loss: 0.1259\n",
      "Epoch 22/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1301 - val_loss: 0.1214\n",
      "Epoch 23/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1274 - val_loss: 0.1205\n",
      "Epoch 24/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.1247 - val_loss: 0.1168\n",
      "Epoch 25/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1210 - val_loss: 0.1127\n",
      "Epoch 26/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.1190 - val_loss: 0.1112\n",
      "Epoch 27/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.1164 - val_loss: 0.1106\n",
      "Epoch 28/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.1137 - val_loss: 0.1067\n",
      "Epoch 29/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1120 - val_loss: 0.1067\n",
      "Epoch 30/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.1095 - val_loss: 0.1046\n",
      "Epoch 31/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.1073 - val_loss: 0.1016\n",
      "Epoch 32/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1047 - val_loss: 0.1001\n",
      "Epoch 33/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1028 - val_loss: 0.0994\n",
      "Epoch 34/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1011 - val_loss: 0.0961\n",
      "Epoch 35/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0987 - val_loss: 0.0966\n",
      "Epoch 36/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0974 - val_loss: 0.0928\n",
      "Epoch 37/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0961 - val_loss: 0.0919\n",
      "Epoch 38/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0943 - val_loss: 0.0900\n",
      "Epoch 39/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0926 - val_loss: 0.0886\n",
      "Epoch 40/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0913 - val_loss: 0.0880\n",
      "Epoch 41/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0905 - val_loss: 0.0869\n",
      "Epoch 42/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0893 - val_loss: 0.0843\n",
      "Epoch 43/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0881 - val_loss: 0.0832\n",
      "Epoch 44/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0868 - val_loss: 0.0823\n",
      "Epoch 45/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0860 - val_loss: 0.0811\n",
      "Epoch 46/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0851 - val_loss: 0.0806\n",
      "Epoch 47/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0847 - val_loss: 0.0800\n",
      "Epoch 48/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0842 - val_loss: 0.0784\n",
      "Epoch 49/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0829 - val_loss: 0.0776\n",
      "Epoch 50/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0824 - val_loss: 0.0784\n",
      "Epoch 51/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0811 - val_loss: 0.0760\n",
      "Epoch 52/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0810 - val_loss: 0.0755\n",
      "Epoch 53/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0801 - val_loss: 0.0752\n",
      "Epoch 54/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0797 - val_loss: 0.0739\n",
      "Epoch 55/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0796 - val_loss: 0.0744\n",
      "Epoch 56/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0790 - val_loss: 0.0749\n",
      "Epoch 57/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0802 - val_loss: 0.0735\n",
      "Epoch 58/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0776 - val_loss: 0.0721\n",
      "Epoch 59/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0775 - val_loss: 0.0727\n",
      "Epoch 60/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0769 - val_loss: 0.0706\n",
      "Epoch 61/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0765 - val_loss: 0.0721\n",
      "Epoch 62/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0762 - val_loss: 0.0724\n",
      "Epoch 63/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0767 - val_loss: 0.0715\n",
      "Epoch 64/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0757 - val_loss: 0.0705\n",
      "Epoch 65/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0754 - val_loss: 0.0707\n",
      "Epoch 66/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0749 - val_loss: 0.0696\n",
      "Epoch 67/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0748 - val_loss: 0.0707\n",
      "Epoch 68/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0751 - val_loss: 0.0690\n",
      "Epoch 68: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/100\n",
      "109/109 [==============================] - 2s 8ms/step - loss: 0.9803 - val_loss: 1.0344\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.6702 - val_loss: 0.7405\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.5333 - val_loss: 0.6772\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.4840 - val_loss: 0.6235\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.4423 - val_loss: 0.5695\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.3996 - val_loss: 0.4896\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.3507 - val_loss: 0.4336\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.2976 - val_loss: 0.3070\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.2419 - val_loss: 0.2270\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1976 - val_loss: 0.1855\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1746 - val_loss: 0.1605\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1615 - val_loss: 0.1514\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1554 - val_loss: 0.1474\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1498 - val_loss: 0.1396\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1422 - val_loss: 0.1361\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1385 - val_loss: 0.1393\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1378 - val_loss: 0.1341\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1315 - val_loss: 0.1308\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1274 - val_loss: 0.1278\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1226 - val_loss: 0.1312\n",
      "Epoch 21/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1193 - val_loss: 0.1230\n",
      "Epoch 22/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1135 - val_loss: 0.1216\n",
      "Epoch 23/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1100 - val_loss: 0.1195\n",
      "Epoch 24/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.1069 - val_loss: 0.1180\n",
      "Epoch 25/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.1183\n",
      "Epoch 26/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1031 - val_loss: 0.1147\n",
      "Epoch 27/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0997 - val_loss: 0.1220\n",
      "Epoch 28/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.1007 - val_loss: 0.1358\n",
      "Epoch 29/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.1089 - val_loss: 0.1226\n",
      "Epoch 30/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0980 - val_loss: 0.1106\n",
      "Epoch 31/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0939 - val_loss: 0.1143\n",
      "Epoch 32/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0955 - val_loss: 0.1061\n",
      "Epoch 33/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0945 - val_loss: 0.1083\n",
      "Epoch 34/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0897 - val_loss: 0.1041\n",
      "Epoch 35/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0883 - val_loss: 0.1024\n",
      "Epoch 36/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0870 - val_loss: 0.1008\n",
      "Epoch 37/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0861 - val_loss: 0.1008\n",
      "Epoch 38/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0857 - val_loss: 0.1006\n",
      "Epoch 39/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0969\n",
      "Epoch 40/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0825 - val_loss: 0.0969\n",
      "Epoch 41/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0825 - val_loss: 0.0962\n",
      "Epoch 42/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0889 - val_loss: 0.1116\n",
      "Epoch 43/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0873 - val_loss: 0.0977\n",
      "Epoch 44/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0812 - val_loss: 0.0933\n",
      "Epoch 45/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0795 - val_loss: 0.0961\n",
      "Epoch 46/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0819 - val_loss: 0.1015\n",
      "Epoch 47/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0819 - val_loss: 0.0907\n",
      "Epoch 48/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0776 - val_loss: 0.0904\n",
      "Epoch 49/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0772 - val_loss: 0.0902\n",
      "Epoch 50/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0771 - val_loss: 0.0917\n",
      "Epoch 51/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0768 - val_loss: 0.0907\n",
      "Epoch 52/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0764 - val_loss: 0.0958\n",
      "Epoch 53/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0779 - val_loss: 0.0876\n",
      "Epoch 54/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0769 - val_loss: 0.0868\n",
      "Epoch 55/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0753 - val_loss: 0.0847\n",
      "Epoch 56/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0734 - val_loss: 0.0846\n",
      "Epoch 57/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0734 - val_loss: 0.0850\n",
      "Epoch 58/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0742 - val_loss: 0.0857\n",
      "Epoch 59/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0730 - val_loss: 0.0829\n",
      "Epoch 60/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0726 - val_loss: 0.0889\n",
      "Epoch 61/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0740 - val_loss: 0.0823\n",
      "Epoch 62/100\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.0727 - val_loss: 0.0832\n",
      "Epoch 63/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0760 - val_loss: 0.0837\n",
      "Epoch 64/100\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.0733 - val_loss: 0.0848\n",
      "Epoch 65/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0733 - val_loss: 0.0811\n",
      "Epoch 66/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0707 - val_loss: 0.0783\n",
      "Epoch 67/100\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0694 - val_loss: 0.0781\n",
      "Epoch 68/100\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.0706 - val_loss: 0.0850\n",
      "Epoch 69/100\n",
      "105/109 [===========================>..] - ETA: 0s - loss: 0.0747"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"\\nRunning round: {i}\\n\")\n",
    "    pool.servers.map(copy_model_to_clients_ae, pool.clients)\n",
    "    pool.clients.map(train_ae)\n",
    "    pool.aggregators.map(weights_collector_ae, pool.clients)\n",
    "    pool.aggregators.map(aggregate_ae)\n",
    "    pool.aggregators.map(set_aggregated_weights_ae, pool.servers)\n",
    "output_model = pool.servers._models[\"autoencoder_server\"][\"model\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_global_model(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    metrics=[\"Accuracy\", \"Precision\", \"F1\", \"Recall\", \"AUC_ROC\"],\n",
    "    threshold=None,\n",
    "):\n",
    "\n",
    "    for i in y.flatten():\n",
    "        if type(i) is not int:\n",
    "            print(type(i))\n",
    "    prediction = model.model.predict(X)\n",
    "    print(prediction.shape)\n",
    "    print(y.flatten().astype(\"int\"))\n",
    "    print(np.mean((X - prediction), axis=2).shape)\n",
    "\n",
    "    d_scores = np.mean((X - prediction), axis=2)\n",
    "\n",
    "    if threshold is None:\n",
    "        threshold = process_scores_with_percentile(d_scores, 0.1)\n",
    "        print(threshold)\n",
    "\n",
    "    l = (d_scores > threshold).astype(\"int\").ravel()\n",
    "    print(l)\n",
    "    model.result_metrics_ = print_metrics(metrics, y.flatten().astype(\"int\"), l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 1s 3ms/step\n",
      "(9328, 30, 38)\n",
      "[1 1 1 ... 1 1 1]\n",
      "(9328, 30)\n",
      "0.002496000272546325\n",
      "[1 0 1 ... 0 1 1]\n",
      "Acc: 67.231% \n",
      "\n",
      "Precision: 0.874 \n",
      "\n",
      "F1score: 0.774 \n",
      "\n",
      "Recall: 0.694 \n",
      "\n",
      "AUC_ROC: 0.638 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_global_model(output_model, X_test_windows, y_test_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.pool.aggregators_stats import aggregate_stats_mean\n",
    "\n",
    "flex_dataset1 = federate_data(5, X_test_windows, y_test_windows)\n",
    "pool._data = flex_dataset1\n",
    "\n",
    "pool.clients.map(evaluate_global_model_clients)\n",
    "thresholds = pool.clients.map(threshold_collector_ae)\n",
    "aggregate_stats_mean(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_global_model(\n",
    "    output_model,\n",
    "    X_test_windows,\n",
    "    y_test_windows,\n",
    "    threshold=aggregate_stats_mean(thresholds),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1bb7960fd30cfaed40cb92889ad99bb2687045b6865895d20dad709adf6b60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
