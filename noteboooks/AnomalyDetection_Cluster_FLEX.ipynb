{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Cluster Model with Flex  for Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to use an Cluster model for anomaly detection with federated learning using the flexible\n",
    "\n",
    "First we do all the imports needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.utils import ClusterAnomaly\n",
    "from flexanomalies.utils.load_data import load_and_split_dot_mat, federate_data\n",
    "from flexanomalies.pool.aggregators_cl import aggregate_cl\n",
    "from flexanomalies.pool.primitives_cluster import (\n",
    "    build_server_model_cl,\n",
    "    copy_model_to_clients_cl,\n",
    "    train_cl,\n",
    "    set_aggregated_weights_cl,\n",
    "    get_clients_weights_cl,\n",
    ")\n",
    "from flexanomalies.utils.save_results import save_experiments_results\n",
    "from flex.pool import FlexPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, define model parameters and define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"n_clusters\": 4, \"contamination\": 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_and_split_dot_mat(\n",
    "    \"flexanomalies/datasets/data/shuttle.mat\", 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClusterAnomaly(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data  is loaded, we have to federate it. For this we use the FLEX library. There are two ways to federate the data, using an IID distribution or a non IID distribution. For the IID distribution we can use the Ã¬id_distribution function of \n",
    "\n",
    "FedDataDistribution. If we use a non-IID distribution, it is necessary to use a custom configuration, such as the one used in the federate_data function. For more information, go to the FLEX library notebooks, and take a look at the Federate Data with \n",
    "\n",
    "FLEXible notebooks.\n",
    "\n",
    "## Creating the federated architecture\n",
    "\n",
    "When creating the federated architecture, we use FlexPool. Since we are running a client-server architecture, we use the client_server_architecture function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dataset = federate_data(5, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = FlexPool.client_server_pool(\n",
    "    fed_dataset=flex_dataset,\n",
    "    server_id=\"cluster_server\",\n",
    "    init_func=build_server_model_cl,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the federated learning experiment and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, we can run the federated experiment for multiple rounds using the decorators. \n",
    "\n",
    "Once the model is trained, we need to evaluate it at the server level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"\\nRunning round: {i}\\n\")\n",
    "    pool.servers.map(copy_model_to_clients_cl, pool.clients)\n",
    "    pool.clients.map(train_cl)\n",
    "    pool.aggregators.map(get_clients_weights_cl, pool.clients)\n",
    "    pool.aggregators.map(aggregate_cl, model=model)\n",
    "    pool.aggregators.map(set_aggregated_weights_cl, pool.servers)\n",
    "output_model = pool.servers._models[\"cluster_server\"][\"model\"]\n",
    "output_model.evaluate(X_test, y_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model.result_metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_experiments_results(\n",
    "    \"cluster\",\n",
    "    output_model,\n",
    "    \"test_cluster_notebook\",\n",
    "    model_params,\n",
    "    \"shuttle.mat\",\n",
    "    5,\n",
    "    3,\n",
    "    0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1bb7960fd30cfaed40cb92889ad99bb2687045b6865895d20dad709adf6b60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
