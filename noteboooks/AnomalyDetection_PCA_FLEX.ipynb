{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated PCA  with Flex  for Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to use an PCA model for anomaly detection with federated learning using the flexible\n",
    "\n",
    "First we do all the imports needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.utils import PCA_Anomaly\n",
    "from flexanomalies.utils.load_data import load_and_split_dot_mat, federate_data\n",
    "from flexanomalies.pool.aggregators_pca import aggregate_pca\n",
    "from flexanomalies.pool.primitives_pca import (\n",
    "    build_server_model_pca,\n",
    "    copy_model_to_clients_pca,\n",
    "    train_pca,\n",
    "    set_aggregated_weights_pca,\n",
    "    get_clients_weights_pca,\n",
    ")\n",
    "from flexanomalies.utils.save_results import save_experiments_results\n",
    "from flex.pool import FlexPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load data, define model parameters and define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"n_components\": 4, \"contamination\": 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_and_split_dot_mat(\n",
    "    \"flexanomalies/datasets/data/shuttle.mat\", 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCA_Anomaly(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data  is loaded, we have to federate it. For this we use the FLEX library. There are two ways to federate the data, using an IID distribution or a non IID distribution. For the IID distribution we can use the Ã¬id_distribution function of \n",
    "\n",
    "FedDataDistribution. If we use a non-IID distribution, it is necessary to use a custom configuration, such as the one used in the federate_data function. For more information, go to the FLEX library workbooks, and take a look at the Federate Data with \n",
    "\n",
    "FLEXible notebooks.\n",
    "\n",
    "## Creating the federated architecture\n",
    "\n",
    "When creating the federated architecture, we use FlexPool. Since we are running a client-server architecture, we use the client_server_architecture function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dataset = federate_data(5, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = FlexPool.client_server_pool(\n",
    "    fed_dataset=flex_dataset,\n",
    "    server_id=\"pca_server\",\n",
    "    init_func=build_server_model_pca,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the federated learning experiment and Evaluate\n",
    "\n",
    "Now, we can run the federated experiment for multiple rounds using the decorators. \n",
    "\n",
    "Once the model is trained, we need to evaluate it at the server level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"\\nRunning round: {i}\\n\")\n",
    "    pool.servers.map(copy_model_to_clients_pca, pool.clients)\n",
    "    pool.clients.map(train_pca)\n",
    "    pool.aggregators.map(get_clients_weights_pca, pool.clients)\n",
    "    pool.aggregators.map(aggregate_pca)\n",
    "    pool.aggregators.map(set_aggregated_weights_pca, pool.servers)\n",
    "output_model = pool.servers._models[\"pca_server\"][\"model\"]\n",
    "output_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model.result_metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_experiments_results(\n",
    "    \"PCA\",\n",
    "    output_model,\n",
    "    \"test_PCA_notebook\",\n",
    "    model_params,\n",
    "    \"shuttle.mat\",\n",
    "    5,\n",
    "    3,\n",
    "    0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1bb7960fd30cfaed40cb92889ad99bb2687045b6865895d20dad709adf6b60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
