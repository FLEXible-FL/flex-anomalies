{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated deep model with Flex for time series anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we do all the imports needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.models import DeepCNN_LSTM\n",
    "from flexanomalies.utils.load_data import split_data, federate_data\n",
    "from flexanomalies.datasets.preprocessing_utils import (\n",
    "    create_windows,\n",
    "    encode_and_bind,\n",
    "    scaling,\n",
    "    impute_lost_values,\n",
    ")\n",
    "from flexanomalies.utils.metrics import print_metrics\n",
    "from flexanomalies.utils.process_scores import (\n",
    "    process_scores_with_percentile,\n",
    "    process_scores_with_threshold,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from flexanomalies.pool.primitives_deepmodel import (\n",
    "    build_server_model_ae,\n",
    "    copy_model_to_clients_ae,\n",
    "    train_ae,\n",
    "    set_aggregated_weights_ae,\n",
    "    weights_collector_ae,\n",
    "    evaluate_global_model,\n",
    "    evaluate_global_model_clients,\n",
    "    threshold_collector_ae,\n",
    ")\n",
    "from flexanomalies.pool.aggregators_favg import aggregate_ae\n",
    "from flexanomalies.utils.save_results import save_experiments_results\n",
    "from flex.pool import FlexPool\n",
    "from flexanomalies.utils.metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../flex-anomalies/flexanomalies/datasets/data/corrected.gz\"\n",
    "split_test = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# process labels\n",
    "df.loc[df[41] != \"normal.\", 41] = 1\n",
    "df.loc[df[41] == \"normal.\", 41] = 0\n",
    "labels = df[41]\n",
    "\n",
    "df = df.drop([41], axis=1)\n",
    "features_to_encode = [1, 2, 3]\n",
    "df = df.drop(features_to_encode, axis=1)\n",
    "\n",
    "# for feature in features_to_encode:\n",
    "#     df = encode_and_bind(df, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"epochs\": 50,\n",
    "    \"input_dim\": df.shape[1],\n",
    "    \"batch_size\": 32,\n",
    "    \"filters_cnn\": [64, 64],\n",
    "    \"units_lstm\": [32],\n",
    "    \"kernel_size\": [9, 9],\n",
    "    \"hidden_act\": [\"relu\", \"relu\"],\n",
    "    \"w_size\": 30,\n",
    "    \"n_pred\": 10,\n",
    "    \"contamination\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaling(np.array(df.iloc[:, :].astype(float)))\n",
    "y = np.array(labels)\n",
    "X_train, X_test, l_train, l_test = split_data(X, y, split_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape == (21769, 30, 38).\n",
      "y_train shape == (21769, 10, 38).\n",
      "X_test shape == (9327, 30, 38).\n",
      "y_test shape == (9327, 10, 38).\n",
      "l_test shape == (93270,).\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    X_train_windows,\n",
    "    y_train_windows,\n",
    "    X_test_windows,\n",
    "    y_test_windows,\n",
    "    l_test_windows,\n",
    ") = create_windows(model_params[\"w_size\"], model_params[\"n_pred\"], X_train, X_test,l_train, l_test)\n",
    "\n",
    "print(\"X_train shape == {}.\".format(np.array(X_train_windows).shape))\n",
    "print(\"y_train shape == {}.\".format(np.array(y_train_windows).shape))\n",
    "print(\"X_test shape == {}.\".format(np.array(X_test_windows).shape))\n",
    "print(\"y_test shape == {}.\".format(np.array(y_test_windows).shape))\n",
    "print(\"l_test shape == {}.\".format(np.array(l_test_windows).shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu 64 9\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 22, 64)            21952     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 11, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 3, 64)             36928     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 1, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1, 32)             12416     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 380)               12540     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 10, 38)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83,836\n",
      "Trainable params: 83,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:40:37.602862: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-01-08 14:40:37.602886: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-01-08 14:40:37.602906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (beatriz-IdeaPad-3-15ITL6): /proc/driver/nvidia/version does not exist\n",
      "2024-01-08 14:40:37.603216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = DeepCNN_LSTM(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dataset = federate_data(5, X_train_windows, y_train_windows)\n",
    "pool = FlexPool.client_server_pool(\n",
    "    fed_dataset=flex_dataset,\n",
    "    server_id=\"cnn_lstm_server\",\n",
    "    init_func=build_server_model_ae,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_global_model(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    labels,\n",
    "    metrics=[\"Accuracy\", \"Precision\", \"F1\", \"Recall\", \"AUC_ROC\"],\n",
    "    threshold=None,\n",
    "):\n",
    "    prediction = model.model.predict(X)\n",
    "    print(prediction.shape)\n",
    "    print(y.shape)\n",
    "    print(np.mean((y - prediction), axis=2).shape)\n",
    "\n",
    "    d_scores = np.mean((y - prediction), axis=2).flatten()\n",
    "    if threshold is None:\n",
    "        threshold = process_scores_with_percentile(d_scores, 0.1)\n",
    "        print(threshold)\n",
    "\n",
    "    l = (d_scores > threshold).astype(\"int\").ravel()\n",
    "    model.result_metrics_ = print_metrics(metrics, labels, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_global_model_clients(client_flex_model, client_data, *args, **kwargs):\n",
    "\n",
    "    X_test, y_test = client_data.to_numpy()\n",
    "    p = client_flex_model[\"model\"].predict(X_test, y_test)\n",
    "\n",
    "    # d_scores = np.linalg.norm(y_test - p, axis=2)\n",
    "    d_scores = np.mean((y_test - p), axis=2).flatten()\n",
    "    threshold = process_scores_with_percentile(d_scores, 0.1)\n",
    "    client_flex_model[\"threshold\"] = threshold\n",
    "    print(\"map\", client_flex_model[\"threshold\"])\n",
    "\n",
    "\n",
    "def threshold_collector_ae(client_model, client_data):\n",
    "    print(\"colect\", client_model[\"threshold\"])\n",
    "    return client_model[\"threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running round: 0\n",
      "\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:40:44         3536\n",
      "variables.h5                                   2024-01-08 14:40:44       361592\n",
      "metadata.json                                  2024-01-08 14:40:44           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:40:44         3536\n",
      "variables.h5                                   2024-01-08 14:40:44       361592\n",
      "metadata.json                                  2024-01-08 14:40:44           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:40:44         3536\n",
      "variables.h5                                   2024-01-08 14:40:44       361592\n",
      "metadata.json                                  2024-01-08 14:40:44           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:40:44         3536\n",
      "variables.h5                                   2024-01-08 14:40:44       361592\n",
      "metadata.json                                  2024-01-08 14:40:44           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:40:44         3536\n",
      "variables.h5                                   2024-01-08 14:40:44       361592\n",
      "metadata.json                                  2024-01-08 14:40:44           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:40:44         3536\n",
      "variables.h5                                   2024-01-08 14:40:44       361592\n",
      "metadata.json                                  2024-01-08 14:40:44           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:40:44         3536\n",
      "variables.h5                                   2024-01-08 14:40:44       361592\n",
      "metadata.json                                  2024-01-08 14:40:44           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:40:44         3536\n",
      "variables.h5                                   2024-01-08 14:40:44       361592\n",
      "metadata.json                                  2024-01-08 14:40:44           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:40:44         3536\n",
      "variables.h5                                   2024-01-08 14:40:44       361592\n",
      "metadata.json                                  2024-01-08 14:40:44           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:40:44         3536\n",
      "variables.h5                                   2024-01-08 14:40:44       361592\n",
      "metadata.json                                  2024-01-08 14:40:44           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 2s 6ms/step - loss: 0.9890 - val_loss: 1.1248\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9888 - val_loss: 1.1249\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1249\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9885 - val_loss: 1.1251\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9873 - val_loss: 1.1250\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9859 - val_loss: 1.1251\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9807 - val_loss: 1.1289\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9712 - val_loss: 1.1261\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9751 - val_loss: 1.1258\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9637 - val_loss: 1.1250\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9502 - val_loss: 1.1250\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9334 - val_loss: 1.1250\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9186 - val_loss: 1.1333\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9099 - val_loss: 1.1315\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9103 - val_loss: 1.1250\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9098 - val_loss: 1.1250\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9513 - val_loss: 1.1251\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9505 - val_loss: 1.1251\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9499 - val_loss: 1.1250\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9499 - val_loss: 1.1250\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9486 - val_loss: 1.1250\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9461 - val_loss: 1.1251\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9444 - val_loss: 1.1251\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9439 - val_loss: 1.1254\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9436 - val_loss: 1.1251\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9436 - val_loss: 1.1256\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9442 - val_loss: 1.1254\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9482 - val_loss: 1.1251\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9464 - val_loss: 1.1251\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9433 - val_loss: 1.1254\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9427 - val_loss: 1.1251\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9427 - val_loss: 1.1252\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9427 - val_loss: 1.1251\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9424 - val_loss: 1.1251\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9421 - val_loss: 1.1251\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9422 - val_loss: 1.1251\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 1.1251\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9434 - val_loss: 1.1251\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9448 - val_loss: 1.1251\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9463 - val_loss: 1.1250\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9454 - val_loss: 1.1251\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9451 - val_loss: 1.1251\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9441 - val_loss: 1.1251\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9442 - val_loss: 1.1251\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9433 - val_loss: 1.1251\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9441 - val_loss: 1.1251\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9442 - val_loss: 1.1251\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9474 - val_loss: 1.1380\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9429 - val_loss: 1.1251\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 4ms/step - loss: 0.9867 - val_loss: 0.8210\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8210\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9863 - val_loss: 0.8212\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9859 - val_loss: 0.8211\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9851 - val_loss: 0.8211\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9815 - val_loss: 0.8213\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9790 - val_loss: 0.8211\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9860 - val_loss: 0.8211\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9719 - val_loss: 0.8211\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9600 - val_loss: 0.8212\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9454 - val_loss: 0.8212\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9189 - val_loss: 0.8211\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8946 - val_loss: 0.8212\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8832 - val_loss: 0.8211\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8576 - val_loss: 0.8211\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8344 - val_loss: 0.8212\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8448 - val_loss: 0.8211\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8491 - val_loss: 0.8212\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8135 - val_loss: 0.8211\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8052 - val_loss: 0.8211\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8074 - val_loss: 0.8211\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8076 - val_loss: 0.8211\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8132 - val_loss: 0.8211\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8131 - val_loss: 0.8211\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8182 - val_loss: 0.8211\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8140 - val_loss: 0.8211\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8142 - val_loss: 0.8211\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8122 - val_loss: 0.8211\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8137 - val_loss: 0.8211\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8100 - val_loss: 0.8211\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8122 - val_loss: 0.8211\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8091 - val_loss: 0.8211\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8206 - val_loss: 0.8211\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8061 - val_loss: 0.8211\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8072 - val_loss: 0.8211\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8071 - val_loss: 0.8211\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8108 - val_loss: 0.8211\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8079 - val_loss: 0.8211\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8143 - val_loss: 0.8211\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8113 - val_loss: 0.8211\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8238 - val_loss: 0.8211\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8149 - val_loss: 0.8211\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8152 - val_loss: 0.8211\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8130 - val_loss: 0.8211\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 2s 5ms/step - loss: 0.7671 - val_loss: 1.2216\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2217\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2220\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7667 - val_loss: 1.2218\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7666 - val_loss: 1.2219\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7664 - val_loss: 1.2219\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7659 - val_loss: 1.2221\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7649 - val_loss: 1.2226\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7630 - val_loss: 1.2256\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7610 - val_loss: 1.2246\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7596 - val_loss: 1.2254\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7557 - val_loss: 1.2273\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7513 - val_loss: 1.2319\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7470 - val_loss: 1.2339\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7432 - val_loss: 1.2340\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7382 - val_loss: 1.2375\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7307 - val_loss: 1.2351\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7287 - val_loss: 1.2411\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7244 - val_loss: 1.2433\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7178 - val_loss: 1.2429\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7091 - val_loss: 1.2437\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7058 - val_loss: 1.2455\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7055 - val_loss: 1.2454\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6973 - val_loss: 1.2579\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6902 - val_loss: 1.2651\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6865 - val_loss: 1.2769\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6833 - val_loss: 1.2519\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6789 - val_loss: 1.2642\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6763 - val_loss: 1.2565\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6731 - val_loss: 1.2622\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6713 - val_loss: 1.2746\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6688 - val_loss: 1.2851\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6660 - val_loss: 1.2724\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6622 - val_loss: 1.2776\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.6604 - val_loss: 1.2684\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.6587 - val_loss: 1.2972\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.6554 - val_loss: 1.2766\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6534 - val_loss: 1.2836\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6510 - val_loss: 1.2769\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6492 - val_loss: 1.2784\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6580 - val_loss: 1.2810\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6491 - val_loss: 1.2700\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6448 - val_loss: 1.2776\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6429 - val_loss: 1.2728\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6423 - val_loss: 1.2668\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6409 - val_loss: 1.2821\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6369 - val_loss: 1.2814\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6353 - val_loss: 1.2793\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6329 - val_loss: 1.2884\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.6321 - val_loss: 1.2871\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.9204 - val_loss: 0.7769\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.7770\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9200 - val_loss: 0.7772\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9199 - val_loss: 0.7771\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9197 - val_loss: 0.7774\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9197 - val_loss: 0.7773\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9188 - val_loss: 0.7773\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9154 - val_loss: 0.7797\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9117 - val_loss: 0.7802\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9151 - val_loss: 0.7786\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9135 - val_loss: 0.7797\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9117 - val_loss: 0.7794\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9063 - val_loss: 0.7790\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9012 - val_loss: 0.7811\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9016 - val_loss: 0.7772\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9172 - val_loss: 0.7799\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9079 - val_loss: 0.7805\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9037 - val_loss: 0.7867\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8958 - val_loss: 0.7826\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8962 - val_loss: 0.7792\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8874 - val_loss: 0.7803\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8808 - val_loss: 0.7884\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8782 - val_loss: 0.7895\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8771 - val_loss: 0.7831\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8781 - val_loss: 0.7908\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8771 - val_loss: 0.7884\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8748 - val_loss: 0.7947\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8735 - val_loss: 0.7889\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8735 - val_loss: 0.7824\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8721 - val_loss: 0.7794\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8742 - val_loss: 0.7827\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8713 - val_loss: 0.7783\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8745 - val_loss: 0.7867\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8708 - val_loss: 0.7781\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8709 - val_loss: 0.7854\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8737 - val_loss: 0.7780\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8599 - val_loss: 0.7851\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8490 - val_loss: 0.7790\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8512 - val_loss: 0.7803\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8416 - val_loss: 0.7814\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8302 - val_loss: 0.7813\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8198 - val_loss: 0.7821\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8159 - val_loss: 0.7814\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8110 - val_loss: 0.7814\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8056 - val_loss: 0.7804\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8021 - val_loss: 0.7814\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7999 - val_loss: 0.7809\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7990 - val_loss: 0.7821\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7973 - val_loss: 0.7816\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 2s 5ms/step - loss: 1.0396 - val_loss: 0.9274\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0394 - val_loss: 0.9275\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0391 - val_loss: 0.9275\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0384 - val_loss: 0.9275\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0345 - val_loss: 0.9286\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0213 - val_loss: 0.9275\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0327 - val_loss: 0.9276\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0032 - val_loss: 0.9276\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9639 - val_loss: 0.9280\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0008 - val_loss: 0.9275\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9371 - val_loss: 0.9277\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8751 - val_loss: 0.9276\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8284 - val_loss: 0.9276\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0266 - val_loss: 0.9276\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0260 - val_loss: 0.9276\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0246 - val_loss: 0.9276\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0236 - val_loss: 0.9275\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0232 - val_loss: 0.9276\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 0.9276\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0226 - val_loss: 0.9276\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0227 - val_loss: 0.9276\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0227 - val_loss: 0.9276\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0228 - val_loss: 0.9276\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0226 - val_loss: 0.9276\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0225 - val_loss: 0.9276\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0225 - val_loss: 0.9276\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0225 - val_loss: 0.9276\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0225 - val_loss: 0.9276\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0224 - val_loss: 0.9276\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0224 - val_loss: 0.9276\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0223 - val_loss: 0.9276\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0223 - val_loss: 0.9276\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0223 - val_loss: 0.9276\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0223 - val_loss: 0.9276\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0224 - val_loss: 0.9276\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0224 - val_loss: 0.9276\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0225 - val_loss: 0.9276\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0224 - val_loss: 0.9276\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0225 - val_loss: 0.9276\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0224 - val_loss: 0.9276\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0228 - val_loss: 0.9276\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0224 - val_loss: 0.9276\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0225 - val_loss: 0.9276\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0223 - val_loss: 0.9276\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0225 - val_loss: 0.9276\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0223 - val_loss: 0.9276\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0227 - val_loss: 0.9276\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0224 - val_loss: 0.9276\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0228 - val_loss: 0.9276\n",
      "\n",
      "Running round: 1\n",
      "\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:42:17         3536\n",
      "variables.h5                                   2024-01-08 14:42:17       361592\n",
      "metadata.json                                  2024-01-08 14:42:17           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:42:16         3536\n",
      "variables.h5                                   2024-01-08 14:42:16       361592\n",
      "metadata.json                                  2024-01-08 14:42:16           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:42:18         3536\n",
      "variables.h5                                   2024-01-08 14:42:18       361592\n",
      "metadata.json                                  2024-01-08 14:42:18           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:42:18         3536\n",
      "variables.h5                                   2024-01-08 14:42:18       361592\n",
      "metadata.json                                  2024-01-08 14:42:18           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:42:18         3536\n",
      "variables.h5                                   2024-01-08 14:42:18       361592\n",
      "metadata.json                                  2024-01-08 14:42:18           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:42:18         3536\n",
      "variables.h5                                   2024-01-08 14:42:18       361592\n",
      "metadata.json                                  2024-01-08 14:42:18           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:42:18         3536\n",
      "variables.h5                                   2024-01-08 14:42:18       361592\n",
      "metadata.json                                  2024-01-08 14:42:18           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:42:18         3536\n",
      "variables.h5                                   2024-01-08 14:42:18       361592\n",
      "metadata.json                                  2024-01-08 14:42:18           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:42:18         3536\n",
      "variables.h5                                   2024-01-08 14:42:18       361592\n",
      "metadata.json                                  2024-01-08 14:42:18           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:42:18         3536\n",
      "variables.h5                                   2024-01-08 14:42:18       361592\n",
      "metadata.json                                  2024-01-08 14:42:18           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.9892 - val_loss: 1.1248\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9889 - val_loss: 1.1248\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9888 - val_loss: 1.1249\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9888 - val_loss: 1.1249\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 4ms/step - loss: 0.9868 - val_loss: 0.8212\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9865 - val_loss: 0.8211\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9863 - val_loss: 0.8210\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9800 - val_loss: 0.8211\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9692 - val_loss: 0.8210\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 2s 5ms/step - loss: 0.7673 - val_loss: 1.2216\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7670 - val_loss: 1.2217\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2217\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2217\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7671 - val_loss: 1.2218\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 4ms/step - loss: 0.9203 - val_loss: 0.7771\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9193 - val_loss: 0.7771\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9173 - val_loss: 0.7771\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9132 - val_loss: 0.7771\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9067 - val_loss: 0.7789\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8991 - val_loss: 0.7772\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8860 - val_loss: 0.7772\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8761 - val_loss: 0.7814\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8688 - val_loss: 0.7783\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8574 - val_loss: 0.7924\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8500 - val_loss: 0.7928\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8378 - val_loss: 0.8174\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8418 - val_loss: 0.8057\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8430 - val_loss: 0.7902\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8286 - val_loss: 0.7864\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8197 - val_loss: 0.7914\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8185 - val_loss: 0.7929\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8205 - val_loss: 0.7893\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8252 - val_loss: 0.7925\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8223 - val_loss: 0.7936\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8197 - val_loss: 0.7948\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8165 - val_loss: 0.7895\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8150 - val_loss: 0.7972\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8153 - val_loss: 0.7909\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8181 - val_loss: 0.7972\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8226 - val_loss: 0.7900\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8150 - val_loss: 0.7934\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8175 - val_loss: 0.8343\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8176 - val_loss: 0.8179\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8208 - val_loss: 0.8365\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8294 - val_loss: 0.7809\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8197 - val_loss: 0.7977\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8211 - val_loss: 0.7915\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8225 - val_loss: 0.7932\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8182 - val_loss: 0.7915\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8139 - val_loss: 0.7935\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8144 - val_loss: 0.7910\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8145 - val_loss: 0.7942\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8160 - val_loss: 0.7893\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8154 - val_loss: 0.7943\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8170 - val_loss: 0.7857\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8169 - val_loss: 0.7933\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8187 - val_loss: 0.7846\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8168 - val_loss: 0.7932\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8181 - val_loss: 0.7848\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8148 - val_loss: 0.7966\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8156 - val_loss: 0.7826\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8149 - val_loss: 0.7994\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8170 - val_loss: 0.7809\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8149 - val_loss: 0.7979\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 2s 4ms/step - loss: 1.0397 - val_loss: 0.9277\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0395 - val_loss: 0.9276\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0394 - val_loss: 0.9275\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0394 - val_loss: 0.9275\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0392 - val_loss: 0.9275\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0384 - val_loss: 0.9275\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0293 - val_loss: 0.9275\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0056 - val_loss: 0.9279\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9622 - val_loss: 0.9360\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9056 - val_loss: 0.9378\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8466 - val_loss: 0.9275\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.8010 - val_loss: 0.9275\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7699 - val_loss: 0.9275\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7567 - val_loss: 0.9275\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7301 - val_loss: 0.9275\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7149 - val_loss: 0.9275\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7160 - val_loss: 0.9275\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7096 - val_loss: 0.9275\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7202 - val_loss: 0.9275\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7048 - val_loss: 0.9275\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7170 - val_loss: 0.9287\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9530 - val_loss: 0.9275\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0394 - val_loss: 0.9275\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "\n",
      "Running round: 2\n",
      "\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:43:56         3536\n",
      "variables.h5                                   2024-01-08 14:43:56       361592\n",
      "metadata.json                                  2024-01-08 14:43:56           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:43:56         3536\n",
      "variables.h5                                   2024-01-08 14:43:56       361592\n",
      "metadata.json                                  2024-01-08 14:43:56           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:43:56         3536\n",
      "variables.h5                                   2024-01-08 14:43:56       361592\n",
      "metadata.json                                  2024-01-08 14:43:56           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:43:56         3536\n",
      "variables.h5                                   2024-01-08 14:43:56       361592\n",
      "metadata.json                                  2024-01-08 14:43:56           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:43:56         3536\n",
      "variables.h5                                   2024-01-08 14:43:56       361592\n",
      "metadata.json                                  2024-01-08 14:43:56           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:43:56         3536\n",
      "variables.h5                                   2024-01-08 14:43:56       361592\n",
      "metadata.json                                  2024-01-08 14:43:56           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:43:56         3536\n",
      "variables.h5                                   2024-01-08 14:43:56       361592\n",
      "metadata.json                                  2024-01-08 14:43:56           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:43:56         3536\n",
      "variables.h5                                   2024-01-08 14:43:56       361592\n",
      "metadata.json                                  2024-01-08 14:43:56           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:43:56         3536\n",
      "variables.h5                                   2024-01-08 14:43:56       361592\n",
      "metadata.json                                  2024-01-08 14:43:56           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-08 14:43:56         3536\n",
      "variables.h5                                   2024-01-08 14:43:56       361592\n",
      "metadata.json                                  2024-01-08 14:43:56           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv1d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......max_pooling1d\n",
      ".........vars\n",
      "......max_pooling1d_1\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 4ms/step - loss: 0.9889 - val_loss: 1.1248\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9888 - val_loss: 1.1249\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9888 - val_loss: 1.1249\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1250\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9889 - val_loss: 1.1250\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.1251\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9885 - val_loss: 1.1251\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9885 - val_loss: 1.1251\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9885 - val_loss: 1.1251\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9886 - val_loss: 1.1251\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.9866 - val_loss: 0.8210\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9865 - val_loss: 0.8210\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9864 - val_loss: 0.8211\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 0.8212\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 2s 5ms/step - loss: 0.7670 - val_loss: 1.2216\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2217\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2217\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2217\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7668 - val_loss: 1.2218\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 1.2218\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 2s 5ms/step - loss: 0.9200 - val_loss: 0.7770\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9141 - val_loss: 0.7781\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9164 - val_loss: 0.7792\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9050 - val_loss: 0.7775\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8943 - val_loss: 0.7784\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.8805 - val_loss: 0.7949\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9204 - val_loss: 0.7771\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7771\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.7772\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 2s 6ms/step - loss: 1.0395 - val_loss: 0.9274\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0394 - val_loss: 0.9274\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0394 - val_loss: 0.9275\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0394 - val_loss: 0.9275\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9275\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0394 - val_loss: 0.9276\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9276\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"\\nRunning round: {i}\\n\")\n",
    "    pool.servers.map(copy_model_to_clients_ae, pool.clients)\n",
    "    pool.clients.map(train_ae)\n",
    "    pool.aggregators.map(weights_collector_ae, pool.clients)\n",
    "    pool.aggregators.map(aggregate_ae)\n",
    "    pool.aggregators.map(set_aggregated_weights_ae, pool.servers)\n",
    "output_model = pool.servers._models[\"cnn_lstm_server\"][\"model\"]\n",
    "\n",
    "# output_model.evaluate(X_test_windows, l_test)7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 0s 1ms/step\n",
      "Acc: 80.231% \n",
      "\n",
      "Precision: 0.974 \n",
      "\n",
      "F1score: 0.864 \n",
      "\n",
      "Recall: 0.776 \n",
      "\n",
      "AUC_ROC: 0.844 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_global_model(output_model, X_test_windows, y_test_windows, l_test_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dataset1 = federate_data(5, X_test_windows, y_test_windows)\n",
    "pool._data = flex_dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 0s 1ms/step\n",
      "137/137 [==============================] - 0s 1ms/step\n",
      "137/137 [==============================] - 0s 1ms/step\n",
      "137/137 [==============================] - 0s 1ms/step\n",
      "137/137 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00036373324154635836"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flexanomalies.pool.aggregators_stats import aggregate_stats_mean\n",
    "\n",
    "pool.clients.map(evaluate_global_model_clients)\n",
    "thresholds = pool.clients.map(threshold_collector_ae)\n",
    "aggregate_stats_mean(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 0s 2ms/step\n",
      "Acc: 80.395% \n",
      "\n",
      "Precision: 0.973 \n",
      "\n",
      "F1score: 0.865 \n",
      "\n",
      "Recall: 0.778 \n",
      "\n",
      "AUC_ROC: 0.845 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_global_model(\n",
    "    output_model,\n",
    "    X_test_windows,\n",
    "    y_test_windows,\n",
    "    l_test_windows,\n",
    "    threshold=aggregate_stats_mean(thresholds),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_experiments_results(\n",
    "    \"cnn_lstm\",\n",
    "    output_model,\n",
    "    \"test_cnn_lstm_notebook\",\n",
    "    model_params,\n",
    "    \"kddcup\",\n",
    "    5,\n",
    "    3,\n",
    "    0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1bb7960fd30cfaed40cb92889ad99bb2687045b6865895d20dad709adf6b60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
