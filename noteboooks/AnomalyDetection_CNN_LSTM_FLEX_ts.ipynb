{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated deep model with Flex for time series anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to use a DeepCNN_LSTM model for time series anomaly detection with federated learning using the flexible tool\n",
    "\n",
    "First we do all the imports needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.utils import DeepCNN_LSTM\n",
    "from flexanomalies.utils.load_data import split_data, federate_data\n",
    "from flexanomalies.datasets.preprocessing_utils import (\n",
    "    create_windows,\n",
    "    encode_and_bind,\n",
    "    scaling,\n",
    "    impute_lost_values,\n",
    ")\n",
    "from flexanomalies.utils.metrics import print_metrics\n",
    "from flexanomalies.utils.process_scores import (\n",
    "    process_scores_with_percentile,\n",
    "    process_scores_with_threshold,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from flexanomalies.pool.primitives_deepmodel import (\n",
    "    build_server_model_ae,\n",
    "    copy_model_to_clients_ae,\n",
    "    train_ae,\n",
    "    set_aggregated_weights_ae,\n",
    "    weights_collector_ae,\n",
    "    evaluate_global_model,\n",
    "    evaluate_global_model_clients,\n",
    "    threshold_collector_ae,\n",
    ")\n",
    "from flexanomalies.pool.aggregators_favg import aggregate_ae\n",
    "from flexanomalies.utils.save_results import save_experiments_results\n",
    "from flex.pool import FlexPool\n",
    "from flexanomalies.utils.metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, preprocessing and define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../flex-anomalies/flexanomalies/datasets/data/corrected.gz\"\n",
    "split_test = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# process labels\n",
    "df.loc[df[41] != \"normal.\", 41] = 1\n",
    "df.loc[df[41] == \"normal.\", 41] = 0\n",
    "labels = df[41]\n",
    "df = df.drop([41], axis=1)\n",
    "features_to_encode = [1, 2, 3]\n",
    "df = df.drop(features_to_encode, axis=1)\n",
    "\n",
    "# for feature in features_to_encode:\n",
    "#     df = encode_and_bind(df, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"epochs\": 50,\n",
    "    \"input_dim\": df.shape[1],\n",
    "    \"batch_size\": 32,\n",
    "    \"filters_cnn\": [32, 32],\n",
    "    \"units_lstm\": [32,32],\n",
    "    \"kernel_size\": [9,9],\n",
    "    \"hidden_act\": [\"relu\", \"relu\"],\n",
    "    \"w_size\": 30,\n",
    "    \"n_pred\": 10,\n",
    "    \"contamination\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scaling, data splitting and sliding window definition:\n",
    "\n",
    "Input window dimensions (window size x number of features) and output dimensions (number of features x number of predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaling(np.array(df.iloc[:, :].astype(float)))\n",
    "y = np.array(labels)\n",
    "X_train, X_test, l_train, l_test = split_data(X, y, split_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train_windows,\n",
    "    y_train_windows,\n",
    "    X_test_windows,\n",
    "    y_test_windows,\n",
    "    l_test_windows,\n",
    ") = create_windows(model_params[\"w_size\"], model_params[\"n_pred\"], X_train, X_test,l_train, l_test)\n",
    "\n",
    "print(\"X_train shape == {}.\".format(np.array(X_train_windows).shape))\n",
    "print(\"y_train shape == {}.\".format(np.array(y_train_windows).shape))\n",
    "print(\"X_test shape == {}.\".format(np.array(X_test_windows).shape))\n",
    "print(\"y_test shape == {}.\".format(np.array(y_test_windows).shape))\n",
    "print(\"l_test shape == {}.\".format(np.array(l_test_windows).shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepCNN_LSTM(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Creating the federated architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data  is loaded and preprocessed, we have to federate it. For this we use the FLEX library. There are two ways to federate the data, using an IID distribution or a non IID distribution. For the IID distribution we can use the Ã¬id_distribution \n",
    "\n",
    "function of FedDataDistribution. If we use a non-IID distribution, it is necessary to use a custom configuration, such as the one used in the federate_data function. For more information, go to the FLEX library workbooks, and take a look at the \n",
    "\n",
    "Federate Data with FLEXible notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dataset = federate_data(5, X_train_windows, y_train_windows)\n",
    "pool = FlexPool.client_server_pool(\n",
    "    fed_dataset=flex_dataset,\n",
    "    server_id=\"cnn_lstm_server\",\n",
    "    init_func=build_server_model_ae,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the federated learning experiment and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the federated experiment for multiple rounds using the decorators\n",
    "\n",
    "Once the model is trained, we need to evaluate it at the server level and at client level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"\\nRunning round: {i}\\n\")\n",
    "    pool.servers.map(copy_model_to_clients_ae, pool.clients)\n",
    "    pool.clients.map(train_ae)\n",
    "    pool.aggregators.map(weights_collector_ae, pool.clients)\n",
    "    pool.aggregators.map(aggregate_ae)\n",
    "    pool.aggregators.map(set_aggregated_weights_ae, pool.servers)\n",
    "output_model = pool.servers._models[\"cnn_lstm_server\"][\"model\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_global_model(output_model, X_test_windows, y_test_windows, l_test_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating at client level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate it at the client level, the function evaluate_global_model_clients is used, which uses the test set in each of the clients, predicts the corresponding values, evaluates and an anomaly threshold is obtained.\n",
    "\n",
    "The threshold_collector_ae function obtains the threshold for each of the clients and the aggregate_stats_mean function performs the aggregation of the thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.pool.aggregators_stats import aggregate_stats_mean\n",
    "\n",
    "pool.clients.map(evaluate_global_model_clients)\n",
    "thresholds = pool.clients.map(threshold_collector_ae)\n",
    "aggregate_stats_mean(thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, the threshold is used to evaluate the model at the server level and perform labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_global_model(\n",
    "    output_model,\n",
    "    X_test_windows,\n",
    "    y_test_windows,\n",
    "    l_test_windows,\n",
    "    threshold=aggregate_stats_mean(thresholds),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_experiments_results(\n",
    "    \"cnn_lstm\",\n",
    "    output_model,\n",
    "    \"test_cnn_lstm_notebook\",\n",
    "    model_params,\n",
    "    \"kddcup\",\n",
    "    5,\n",
    "    3,\n",
    "    0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1bb7960fd30cfaed40cb92889ad99bb2687045b6865895d20dad709adf6b60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
