{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated AutoEncoder  with Flex  for Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to use an Auto Encoder model for anomaly detection with federated learning using the flexible\n",
    "\n",
    "First we do all the imports needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.utils import AutoEncoder\n",
    "from flexanomalies.utils.load_data import load_and_split_dot_mat, federate_data\n",
    "from flexanomalies.pool.aggregators_favg import aggregate_ae\n",
    "from flexanomalies.pool.primitives_deepmodel import (\n",
    "    build_server_model_ae,\n",
    "    copy_model_to_clients_ae,\n",
    "    train_ae,\n",
    "    set_aggregated_weights_ae,\n",
    "    weights_collector_ae,\n",
    ")\n",
    "from flexanomalies.utils.save_results import save_experiments_results\n",
    "from flex.pool import FlexPool\n",
    "from flexanomalies.utils.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"epochs\": 50,\n",
    "    \"input_dim\": 9,\n",
    "    \"batch_size\": 32,\n",
    "    \"neurons\": [8, 4, 8],\n",
    "    \"hidden_act\": [\"relu\", \"relu\", \"relu\"],\n",
    "    \"contamination\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_and_split_dot_mat(\n",
    "    \"flexanomalies/datasets/data/shuttle.mat\", 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data  is loaded, we have to federate it. For this we use the FLEX library. There are two ways to federate the data, using an IID distribution or a non IID distribution. For the IID distribution we can use the Ã¬id_distribution function of \n",
    "\n",
    "FedDataDistribution. If we use a non-IID distribution, it is necessary to use a custom configuration, such as the one used in the federate_data function. For more information, go to the FLEX library workbooks, and take a look at the Federate Data with \n",
    "\n",
    "FLEXible notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dataset = federate_data(5, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the federated architecture\n",
    "\n",
    "When creating the federated architecture, we use FlexPool. Since we are running a client-server architecture, we use the client_server_architecture function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = FlexPool.client_server_pool(\n",
    "    fed_dataset=flex_dataset,\n",
    "    server_id=\"autoencoder_server\",\n",
    "    init_func=build_server_model_ae,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the federated learning experiment and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the federated experiment for multiple rounds using the decorators. \n",
    "\n",
    "Once the model is trained, we need to evaluate it at the server level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"\\nRunning round: {i}\\n\")\n",
    "    pool.servers.map(copy_model_to_clients_ae, pool.clients)\n",
    "    pool.clients.map(train_ae)\n",
    "    pool.aggregators.map(weights_collector_ae, pool.clients)\n",
    "    pool.aggregators.map(aggregate_ae)\n",
    "    pool.aggregators.map(set_aggregated_weights_ae, pool.servers)\n",
    "output_model = pool.servers._models[\"autoencoder_server\"][\"model\"]\n",
    "output_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model.result_metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_experiments_results(\n",
    "    \"autoencoder\",\n",
    "    output_model,\n",
    "    \"test_autoencoder_notebook\",\n",
    "    model_params,\n",
    "    \"shuttle.mat\",\n",
    "    5,\n",
    "    3,\n",
    "    0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1bb7960fd30cfaed40cb92889ad99bb2687045b6865895d20dad709adf6b60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
