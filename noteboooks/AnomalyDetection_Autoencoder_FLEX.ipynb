{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated AutoEncoder  with Flex  for Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we do all the imports needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.utils import AutoEncoder\n",
    "from flexanomalies.utils.load_data import load_and_split_dot_mat, federate_data\n",
    "from flexanomalies.pool.aggregators_favg import aggregate_ae\n",
    "from flexanomalies.pool.primitives_deepmodel import (\n",
    "    build_server_model_ae,\n",
    "    copy_model_to_clients_ae,\n",
    "    train_ae,\n",
    "    set_aggregated_weights_ae,\n",
    "    weights_collector_ae,\n",
    ")\n",
    "from flexanomalies.utils.save_results import save_experiments_results\n",
    "from flex.pool import FlexPool\n",
    "from flexanomalies.utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"epochs\": 50,\n",
    "    \"input_dim\": 9,\n",
    "    \"batch_size\": 32,\n",
    "    \"neurons\": [8, 4, 8],\n",
    "    \"hidden_act\": [\"relu\", \"relu\", \"relu\"],\n",
    "    \"contamination\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_and_split_dot_mat(\n",
    "    \"flexanomalies/datasets/data/shuttle.mat\", 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dataset = federate_data(5, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = FlexPool.client_server_pool(\n",
    "    fed_dataset=flex_dataset,\n",
    "    server_id=\"autoencoder_server\",\n",
    "    init_func=build_server_model_ae,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running round: 0\n",
      "\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:46:34         2228\n",
      "variables.h5                                   2023-12-14 11:46:34        17680\n",
      "metadata.json                                  2023-12-14 11:46:34           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:46:34         2228\n",
      "variables.h5                                   2023-12-14 11:46:34        17680\n",
      "metadata.json                                  2023-12-14 11:46:34           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:46:34         2228\n",
      "variables.h5                                   2023-12-14 11:46:34        17680\n",
      "metadata.json                                  2023-12-14 11:46:34           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:46:34         2228\n",
      "variables.h5                                   2023-12-14 11:46:34        17680\n",
      "metadata.json                                  2023-12-14 11:46:34           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:46:34         2228\n",
      "variables.h5                                   2023-12-14 11:46:34        17680\n",
      "metadata.json                                  2023-12-14 11:46:34           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:46:34         2228\n",
      "variables.h5                                   2023-12-14 11:46:34        17680\n",
      "metadata.json                                  2023-12-14 11:46:34           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:46:34         2228\n",
      "variables.h5                                   2023-12-14 11:46:34        17680\n",
      "metadata.json                                  2023-12-14 11:46:34           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:46:34         2228\n",
      "variables.h5                                   2023-12-14 11:46:34        17680\n",
      "metadata.json                                  2023-12-14 11:46:34           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:46:34         2228\n",
      "variables.h5                                   2023-12-14 11:46:34        17680\n",
      "metadata.json                                  2023-12-14 11:46:34           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:46:34         2228\n",
      "variables.h5                                   2023-12-14 11:46:34        17680\n",
      "metadata.json                                  2023-12-14 11:46:34           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 2ms/step - loss: 0.9093 - val_loss: 1.3226\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.8014 - val_loss: 1.0980\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.5522 - val_loss: 0.9322\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.4536 - val_loss: 0.8728\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.8146\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.7794\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3185 - val_loss: 0.7642\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.7635\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2946 - val_loss: 0.7584\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2883 - val_loss: 0.7562\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.7513\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 0.7501\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2763 - val_loss: 0.7433\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 0s 982us/step - loss: 0.2732 - val_loss: 0.7406\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2706 - val_loss: 0.7354\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2684 - val_loss: 0.7323\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2657 - val_loss: 0.7316\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2632 - val_loss: 0.7258\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2621 - val_loss: 0.7250\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2595 - val_loss: 0.7253\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2558 - val_loss: 0.7255\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2536 - val_loss: 0.7217\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2510 - val_loss: 0.7205\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2475 - val_loss: 0.7214\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2441 - val_loss: 0.7217\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2406 - val_loss: 0.7209\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2365 - val_loss: 0.7180\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2326 - val_loss: 0.7170\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2272 - val_loss: 0.7197\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2225 - val_loss: 0.7172\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2165 - val_loss: 0.7229\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2110 - val_loss: 0.7159\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2045 - val_loss: 0.7035\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1969 - val_loss: 0.7026\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1894 - val_loss: 0.6998\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1828 - val_loss: 0.6919\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1770 - val_loss: 0.6958\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1707 - val_loss: 0.6959\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1660 - val_loss: 0.6887\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1620 - val_loss: 0.6885\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1599 - val_loss: 0.6627\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1568 - val_loss: 0.6721\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1533 - val_loss: 0.6427\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1501 - val_loss: 0.6373\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1470 - val_loss: 0.6320\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1434 - val_loss: 0.6280\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1411 - val_loss: 0.6169\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1376 - val_loss: 0.6033\n",
      "Epoch 49/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1350 - val_loss: 0.6026\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1325 - val_loss: 0.6032\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 2ms/step - loss: 0.9980 - val_loss: 0.9396\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.9218 - val_loss: 0.8761\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.8680 - val_loss: 0.8132\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.7888 - val_loss: 0.7215\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.7224 - val_loss: 0.6521\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.6567 - val_loss: 0.5468\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.5761 - val_loss: 0.4600\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.5193 - val_loss: 0.4011\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.4743 - val_loss: 0.3534\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.3221\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.4182 - val_loss: 0.3027\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.2865\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3906 - val_loss: 0.2758\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.2685\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.2586\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.2542\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3042 - val_loss: 0.2523\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2859 - val_loss: 0.2490\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2752 - val_loss: 0.2543\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2653 - val_loss: 0.2530\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2600 - val_loss: 0.2535\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2568 - val_loss: 0.2517\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2536 - val_loss: 0.2497\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2510 - val_loss: 0.2485\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2519 - val_loss: 0.2515\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2464 - val_loss: 0.2475\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2444 - val_loss: 0.2417\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2426 - val_loss: 0.2422\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2408 - val_loss: 0.2390\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2417 - val_loss: 0.2321\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2359 - val_loss: 0.2279\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2327 - val_loss: 0.2270\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2298 - val_loss: 0.2253\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2286 - val_loss: 0.2185\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2284 - val_loss: 0.2197\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2219 - val_loss: 0.2114\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2181 - val_loss: 0.2060\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2149 - val_loss: 0.2006\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2119 - val_loss: 0.2004\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2086 - val_loss: 0.1961\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2107 - val_loss: 0.1866\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2044 - val_loss: 0.1867\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2003 - val_loss: 0.1865\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2029 - val_loss: 0.1772\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1986 - val_loss: 0.1799\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1957 - val_loss: 0.1716\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1920 - val_loss: 0.1725\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1926 - val_loss: 0.1714\n",
      "Epoch 49/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1890 - val_loss: 0.1679\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1892 - val_loss: 0.1726\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 1.0762 - val_loss: 0.7579\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.9950 - val_loss: 0.6199\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.7804 - val_loss: 0.4116\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.6378 - val_loss: 0.3300\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.5581 - val_loss: 0.2750\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.5024 - val_loss: 0.2395\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.4678 - val_loss: 0.2197\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 0.2043\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.4318 - val_loss: 0.1949\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 990us/step - loss: 0.4212 - val_loss: 0.1880\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 996us/step - loss: 0.4119 - val_loss: 0.1821\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 0s 990us/step - loss: 0.4055 - val_loss: 0.1790\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 0s 999us/step - loss: 0.4015 - val_loss: 0.1761\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.1735\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.1724\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.1700\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 0s 998us/step - loss: 0.3899 - val_loss: 0.1686\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.1681\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.1696\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.1659\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 0s 975us/step - loss: 0.3851 - val_loss: 0.1658\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.1638\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.1643\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 0s 1000us/step - loss: 0.3829 - val_loss: 0.1628\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.1656\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.1628\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.1624\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.1613\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.1605\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.1610\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.1604\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.1601\n",
      "Epoch 32: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 0.9208 - val_loss: 1.2027\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.7636 - val_loss: 0.8596\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 997us/step - loss: 0.5260 - val_loss: 0.7776\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.4503 - val_loss: 0.7314\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 982us/step - loss: 0.3834 - val_loss: 0.6730\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 996us/step - loss: 0.3271 - val_loss: 0.6421\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3012 - val_loss: 0.6304\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2884 - val_loss: 0.6229\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 0.6205\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2710 - val_loss: 0.6167\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2636 - val_loss: 0.6091\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2544 - val_loss: 0.6010\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2454 - val_loss: 0.5946\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 0s 997us/step - loss: 0.2332 - val_loss: 0.5840\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 0s 997us/step - loss: 0.2212 - val_loss: 0.5780\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 0s 992us/step - loss: 0.2093 - val_loss: 0.5687\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 0s 993us/step - loss: 0.1979 - val_loss: 0.5618\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 0s 980us/step - loss: 0.1871 - val_loss: 0.5528\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1795 - val_loss: 0.5529\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 0s 984us/step - loss: 0.1740 - val_loss: 0.5507\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1700 - val_loss: 0.5453\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1672 - val_loss: 0.5447\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1651 - val_loss: 0.5421\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1637 - val_loss: 0.5390\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1628 - val_loss: 0.5411\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1626 - val_loss: 0.5375\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1608 - val_loss: 0.5331\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.5390\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1594 - val_loss: 0.5313\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1594 - val_loss: 0.5326\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1577 - val_loss: 0.5336\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1574 - val_loss: 0.5305\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1585 - val_loss: 0.5315\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1561 - val_loss: 0.5260\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1551 - val_loss: 0.5267\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1544 - val_loss: 0.5242\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1541 - val_loss: 0.5302\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1536 - val_loss: 0.5182\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1540 - val_loss: 0.5204\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1524 - val_loss: 0.5128\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1518 - val_loss: 0.5173\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1514 - val_loss: 0.5121\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1522 - val_loss: 0.5120\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1510 - val_loss: 0.5139\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 0s 981us/step - loss: 0.1502 - val_loss: 0.5096\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 0s 908us/step - loss: 0.1493 - val_loss: 0.5016\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 0s 867us/step - loss: 0.1480 - val_loss: 0.5034\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 0s 865us/step - loss: 0.1487 - val_loss: 0.4998\n",
      "Epoch 49/50\n",
      "172/172 [==============================] - 0s 860us/step - loss: 0.1480 - val_loss: 0.5039\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1475 - val_loss: 0.4970\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 1.0775 - val_loss: 0.6116\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 915us/step - loss: 0.9978 - val_loss: 0.5615\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 856us/step - loss: 0.9545 - val_loss: 0.5393\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 834us/step - loss: 0.9232 - val_loss: 0.5037\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 900us/step - loss: 0.8601 - val_loss: 0.4426\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 854us/step - loss: 0.7917 - val_loss: 0.4037\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 904us/step - loss: 0.7435 - val_loss: 0.3750\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 897us/step - loss: 0.7031 - val_loss: 0.3545\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 857us/step - loss: 0.6678 - val_loss: 0.3374\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 883us/step - loss: 0.6343 - val_loss: 0.3219\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 860us/step - loss: 0.5962 - val_loss: 0.2938\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 0s 843us/step - loss: 0.5512 - val_loss: 0.2585\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 0s 836us/step - loss: 0.4952 - val_loss: 0.2123\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.1725\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.1434\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 0s 870us/step - loss: 0.3610 - val_loss: 0.1226\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 0s 911us/step - loss: 0.3403 - val_loss: 0.1103\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 0s 924us/step - loss: 0.3246 - val_loss: 0.1019\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 0s 885us/step - loss: 0.3144 - val_loss: 0.0958\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 0s 858us/step - loss: 0.3052 - val_loss: 0.0918\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 0s 842us/step - loss: 0.2979 - val_loss: 0.0898\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 0s 853us/step - loss: 0.2921 - val_loss: 0.0862\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 0s 851us/step - loss: 0.2870 - val_loss: 0.0842\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 0s 842us/step - loss: 0.2825 - val_loss: 0.0814\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 0s 838us/step - loss: 0.2781 - val_loss: 0.0802\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 0s 892us/step - loss: 0.2737 - val_loss: 0.0781\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 0s 839us/step - loss: 0.2697 - val_loss: 0.0776\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 0s 902us/step - loss: 0.2646 - val_loss: 0.0763\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 0s 995us/step - loss: 0.2598 - val_loss: 0.0762\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 0s 967us/step - loss: 0.2561 - val_loss: 0.0742\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 0s 914us/step - loss: 0.2502 - val_loss: 0.0721\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 0s 872us/step - loss: 0.2468 - val_loss: 0.0717\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2407 - val_loss: 0.0722\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 0s 943us/step - loss: 0.2354 - val_loss: 0.0724\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 0s 941us/step - loss: 0.2305 - val_loss: 0.0707\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 0s 986us/step - loss: 0.2251 - val_loss: 0.0698\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 0s 973us/step - loss: 0.2207 - val_loss: 0.0687\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 0s 877us/step - loss: 0.2166 - val_loss: 0.0709\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2123 - val_loss: 0.0682\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 0s 951us/step - loss: 0.2082 - val_loss: 0.0652\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 0s 978us/step - loss: 0.2051 - val_loss: 0.0652\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 0s 940us/step - loss: 0.2016 - val_loss: 0.0652\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 0s 894us/step - loss: 0.1978 - val_loss: 0.0648\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 0s 878us/step - loss: 0.1962 - val_loss: 0.0647\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1940 - val_loss: 0.0640\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1933 - val_loss: 0.0658\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1912 - val_loss: 0.0644\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1881 - val_loss: 0.0639\n",
      "Epoch 49/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1872 - val_loss: 0.0642\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1855 - val_loss: 0.0642\n",
      "Epoch 50: early stopping\n",
      "\n",
      "Running round: 1\n",
      "\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:20         2228\n",
      "variables.h5                                   2023-12-14 11:47:20        17680\n",
      "metadata.json                                  2023-12-14 11:47:20           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:20         2228\n",
      "variables.h5                                   2023-12-14 11:47:20        17680\n",
      "metadata.json                                  2023-12-14 11:47:20           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:20         2228\n",
      "variables.h5                                   2023-12-14 11:47:20        17680\n",
      "metadata.json                                  2023-12-14 11:47:20           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:20         2228\n",
      "variables.h5                                   2023-12-14 11:47:20        17680\n",
      "metadata.json                                  2023-12-14 11:47:20           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:20         2228\n",
      "variables.h5                                   2023-12-14 11:47:20        17680\n",
      "metadata.json                                  2023-12-14 11:47:20           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:20         2228\n",
      "variables.h5                                   2023-12-14 11:47:20        17680\n",
      "metadata.json                                  2023-12-14 11:47:20           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:20         2228\n",
      "variables.h5                                   2023-12-14 11:47:20        17680\n",
      "metadata.json                                  2023-12-14 11:47:20           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:20         2228\n",
      "variables.h5                                   2023-12-14 11:47:20        17680\n",
      "metadata.json                                  2023-12-14 11:47:20           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:20         2228\n",
      "variables.h5                                   2023-12-14 11:47:20        17680\n",
      "metadata.json                                  2023-12-14 11:47:20           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:20         2228\n",
      "variables.h5                                   2023-12-14 11:47:20        17680\n",
      "metadata.json                                  2023-12-14 11:47:20           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 2ms/step - loss: 0.4624 - val_loss: 0.5617\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3144 - val_loss: 0.5379\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 889us/step - loss: 0.2914 - val_loss: 0.5299\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 879us/step - loss: 0.2768 - val_loss: 0.5246\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2638 - val_loss: 0.5216\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2528 - val_loss: 0.5184\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.2391 - val_loss: 0.5179\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2265 - val_loss: 0.5154\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 994us/step - loss: 0.2137 - val_loss: 0.5138\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 970us/step - loss: 0.2016 - val_loss: 0.5132\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1918 - val_loss: 0.5152\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1834 - val_loss: 0.5131\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 0s 985us/step - loss: 0.1772 - val_loss: 0.5139\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 0s 885us/step - loss: 0.1723 - val_loss: 0.5138\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 0s 891us/step - loss: 0.1681 - val_loss: 0.5126\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 0s 883us/step - loss: 0.1645 - val_loss: 0.5154\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 0s 910us/step - loss: 0.1613 - val_loss: 0.5183\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1574 - val_loss: 0.5173\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 0s 997us/step - loss: 0.1558 - val_loss: 0.5140\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 0s 981us/step - loss: 0.1500 - val_loss: 0.5147\n",
      "Epoch 20: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 0.5642 - val_loss: 0.3099\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 953us/step - loss: 0.4072 - val_loss: 0.2679\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 959us/step - loss: 0.3835 - val_loss: 0.2573\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 907us/step - loss: 0.3693 - val_loss: 0.2530\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 883us/step - loss: 0.3627 - val_loss: 0.2531\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 962us/step - loss: 0.3573 - val_loss: 0.2492\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 974us/step - loss: 0.3510 - val_loss: 0.2480\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 900us/step - loss: 0.3462 - val_loss: 0.2468\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 864us/step - loss: 0.3411 - val_loss: 0.2472\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 847us/step - loss: 0.3366 - val_loss: 0.2440\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 881us/step - loss: 0.3316 - val_loss: 0.2457\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 0s 879us/step - loss: 0.3260 - val_loss: 0.2448\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 0s 936us/step - loss: 0.3239 - val_loss: 0.2503\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 0s 924us/step - loss: 0.3184 - val_loss: 0.2429\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 0s 955us/step - loss: 0.3130 - val_loss: 0.2446\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 0s 856us/step - loss: 0.3071 - val_loss: 0.2482\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 0s 859us/step - loss: 0.3049 - val_loss: 0.2454\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 0s 882us/step - loss: 0.2997 - val_loss: 0.2452\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 0s 851us/step - loss: 0.2957 - val_loss: 0.2493\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 0s 855us/step - loss: 0.2922 - val_loss: 0.2458\n",
      "Epoch 20: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 0.5723 - val_loss: 0.3048\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 858us/step - loss: 0.4327 - val_loss: 0.2704\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 874us/step - loss: 0.4039 - val_loss: 0.2591\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 895us/step - loss: 0.3903 - val_loss: 0.2541\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 861us/step - loss: 0.3828 - val_loss: 0.2554\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 848us/step - loss: 0.3790 - val_loss: 0.2509\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 862us/step - loss: 0.3753 - val_loss: 0.2480\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 855us/step - loss: 0.3723 - val_loss: 0.2472\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 871us/step - loss: 0.3697 - val_loss: 0.2478\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 860us/step - loss: 0.3689 - val_loss: 0.2505\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 856us/step - loss: 0.3672 - val_loss: 0.2437\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 0s 850us/step - loss: 0.3644 - val_loss: 0.2430\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 0s 849us/step - loss: 0.3648 - val_loss: 0.2442\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 0s 862us/step - loss: 0.3638 - val_loss: 0.2430\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 0s 850us/step - loss: 0.3619 - val_loss: 0.2445\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 0s 907us/step - loss: 0.3610 - val_loss: 0.2428\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 0s 843us/step - loss: 0.3610 - val_loss: 0.2438\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 0s 859us/step - loss: 0.3594 - val_loss: 0.2427\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 0s 864us/step - loss: 0.3604 - val_loss: 0.2452\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 0s 835us/step - loss: 0.3589 - val_loss: 0.2441\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 0s 864us/step - loss: 0.3590 - val_loss: 0.2430\n",
      "Epoch 21: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 0.4995 - val_loss: 0.4555\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 856us/step - loss: 0.3409 - val_loss: 0.4080\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 832us/step - loss: 0.3169 - val_loss: 0.3932\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 826us/step - loss: 0.3049 - val_loss: 0.3788\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 903us/step - loss: 0.2951 - val_loss: 0.3699\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 838us/step - loss: 0.2839 - val_loss: 0.3587\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 817us/step - loss: 0.2742 - val_loss: 0.3470\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 836us/step - loss: 0.2638 - val_loss: 0.3420\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 854us/step - loss: 0.2530 - val_loss: 0.3266\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 852us/step - loss: 0.2403 - val_loss: 0.3129\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 887us/step - loss: 0.2320 - val_loss: 0.3110\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 0s 835us/step - loss: 0.2204 - val_loss: 0.2943\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 0s 822us/step - loss: 0.2097 - val_loss: 0.2913\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 0s 850us/step - loss: 0.2022 - val_loss: 0.2800\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 0s 853us/step - loss: 0.1955 - val_loss: 0.2784\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 0s 869us/step - loss: 0.1900 - val_loss: 0.2694\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 0s 960us/step - loss: 0.1868 - val_loss: 0.2685\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 0s 934us/step - loss: 0.1825 - val_loss: 0.2689\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 0s 874us/step - loss: 0.1801 - val_loss: 0.2558\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 0s 863us/step - loss: 0.1782 - val_loss: 0.2547\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 0s 845us/step - loss: 0.1751 - val_loss: 0.2572\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 0s 840us/step - loss: 0.1719 - val_loss: 0.2447\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 0s 997us/step - loss: 0.1714 - val_loss: 0.2452\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 0s 839us/step - loss: 0.1668 - val_loss: 0.2408\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 0s 845us/step - loss: 0.1638 - val_loss: 0.2274\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 0s 849us/step - loss: 0.1639 - val_loss: 0.2291\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 0s 851us/step - loss: 0.1609 - val_loss: 0.2245\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 0s 862us/step - loss: 0.1576 - val_loss: 0.2218\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 0s 887us/step - loss: 0.1547 - val_loss: 0.2080\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 0s 854us/step - loss: 0.1533 - val_loss: 0.2113\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 0s 849us/step - loss: 0.1509 - val_loss: 0.2043\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 0s 842us/step - loss: 0.1485 - val_loss: 0.1925\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 0s 864us/step - loss: 0.1480 - val_loss: 0.1913\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 0s 862us/step - loss: 0.1445 - val_loss: 0.1912\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 0s 892us/step - loss: 0.1420 - val_loss: 0.1893\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 0s 861us/step - loss: 0.1409 - val_loss: 0.1831\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 0s 853us/step - loss: 0.1395 - val_loss: 0.1810\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 0s 835us/step - loss: 0.1380 - val_loss: 0.1753\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 0s 939us/step - loss: 0.1375 - val_loss: 0.1752\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 0s 929us/step - loss: 0.1363 - val_loss: 0.1729\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 0s 956us/step - loss: 0.1353 - val_loss: 0.1724\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 0s 934us/step - loss: 0.1348 - val_loss: 0.1726\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 0s 875us/step - loss: 0.1383 - val_loss: 0.1747\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 0s 858us/step - loss: 0.1337 - val_loss: 0.1679\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 0s 868us/step - loss: 0.1329 - val_loss: 0.1629\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 0s 867us/step - loss: 0.1325 - val_loss: 0.1665\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 0s 907us/step - loss: 0.1322 - val_loss: 0.1633\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 0s 847us/step - loss: 0.1319 - val_loss: 0.1638\n",
      "Epoch 49/50\n",
      "172/172 [==============================] - 0s 849us/step - loss: 0.1311 - val_loss: 0.1605\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 0s 883us/step - loss: 0.1306 - val_loss: 0.1624\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 0.5250 - val_loss: 0.3652\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 843us/step - loss: 0.3988 - val_loss: 0.3217\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 835us/step - loss: 0.3753 - val_loss: 0.3011\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 845us/step - loss: 0.3661 - val_loss: 0.2870\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 867us/step - loss: 0.3604 - val_loss: 0.2754\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 839us/step - loss: 0.3555 - val_loss: 0.2658\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 840us/step - loss: 0.3499 - val_loss: 0.2491\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 851us/step - loss: 0.3453 - val_loss: 0.2396\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 860us/step - loss: 0.3400 - val_loss: 0.2267\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 848us/step - loss: 0.3355 - val_loss: 0.2184\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 864us/step - loss: 0.3289 - val_loss: 0.2060\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 0s 843us/step - loss: 0.3234 - val_loss: 0.1929\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 0s 847us/step - loss: 0.3178 - val_loss: 0.1804\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 0s 852us/step - loss: 0.3114 - val_loss: 0.1734\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 0s 856us/step - loss: 0.3056 - val_loss: 0.1629\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 0s 835us/step - loss: 0.2990 - val_loss: 0.1589\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 0s 876us/step - loss: 0.2939 - val_loss: 0.1582\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 0s 831us/step - loss: 0.2909 - val_loss: 0.1559\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 0s 860us/step - loss: 0.2871 - val_loss: 0.1612\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 0s 872us/step - loss: 0.2836 - val_loss: 0.1599\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 0s 855us/step - loss: 0.2821 - val_loss: 0.1650\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 0s 832us/step - loss: 0.2808 - val_loss: 0.1700\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 0s 873us/step - loss: 0.2796 - val_loss: 0.1814\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 0s 840us/step - loss: 0.2794 - val_loss: 0.1794\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 0s 846us/step - loss: 0.2791 - val_loss: 0.1815\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 0s 853us/step - loss: 0.2783 - val_loss: 0.1895\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 0s 839us/step - loss: 0.2777 - val_loss: 0.1870\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 0s 862us/step - loss: 0.2768 - val_loss: 0.1863\n",
      "Epoch 28: early stopping\n",
      "\n",
      "Running round: 2\n",
      "\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:45         2228\n",
      "variables.h5                                   2023-12-14 11:47:45        17680\n",
      "metadata.json                                  2023-12-14 11:47:45           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:44         2228\n",
      "variables.h5                                   2023-12-14 11:47:44        17680\n",
      "metadata.json                                  2023-12-14 11:47:44           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:45         2228\n",
      "variables.h5                                   2023-12-14 11:47:45        17680\n",
      "metadata.json                                  2023-12-14 11:47:45           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:44         2228\n",
      "variables.h5                                   2023-12-14 11:47:44        17680\n",
      "metadata.json                                  2023-12-14 11:47:44           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:45         2228\n",
      "variables.h5                                   2023-12-14 11:47:45        17680\n",
      "metadata.json                                  2023-12-14 11:47:45           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:44         2228\n",
      "variables.h5                                   2023-12-14 11:47:44        17680\n",
      "metadata.json                                  2023-12-14 11:47:44           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:45         2228\n",
      "variables.h5                                   2023-12-14 11:47:45        17680\n",
      "metadata.json                                  2023-12-14 11:47:45           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:44         2228\n",
      "variables.h5                                   2023-12-14 11:47:44        17680\n",
      "metadata.json                                  2023-12-14 11:47:44           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:45         2228\n",
      "variables.h5                                   2023-12-14 11:47:45        17680\n",
      "metadata.json                                  2023-12-14 11:47:45           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-14 11:47:44         2228\n",
      "variables.h5                                   2023-12-14 11:47:44        17680\n",
      "metadata.json                                  2023-12-14 11:47:44           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 0.3365 - val_loss: 0.0392\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 847us/step - loss: 0.3234 - val_loss: 0.0388\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 845us/step - loss: 0.3122 - val_loss: 0.0429\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 856us/step - loss: 0.3027 - val_loss: 0.0451\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 846us/step - loss: 0.2935 - val_loss: 0.0437\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 852us/step - loss: 0.2860 - val_loss: 0.0475\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 848us/step - loss: 0.2785 - val_loss: 0.0499\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 854us/step - loss: 0.2714 - val_loss: 0.0478\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 852us/step - loss: 0.2648 - val_loss: 0.0519\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 832us/step - loss: 0.2588 - val_loss: 0.0549\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 829us/step - loss: 0.2520 - val_loss: 0.0573\n",
      "Epoch 11: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 0.3280 - val_loss: 0.1489\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 883us/step - loss: 0.3218 - val_loss: 0.1478\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 827us/step - loss: 0.3148 - val_loss: 0.1492\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 841us/step - loss: 0.3104 - val_loss: 0.1494\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 845us/step - loss: 0.3066 - val_loss: 0.1505\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 823us/step - loss: 0.3022 - val_loss: 0.1526\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 838us/step - loss: 0.2987 - val_loss: 0.1509\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 831us/step - loss: 0.2965 - val_loss: 0.1511\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 864us/step - loss: 0.2939 - val_loss: 0.1526\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 833us/step - loss: 0.2923 - val_loss: 0.1520\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 840us/step - loss: 0.2906 - val_loss: 0.1531\n",
      "Epoch 11: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 0.3988 - val_loss: 0.1152\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 967us/step - loss: 0.3929 - val_loss: 0.1189\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 846us/step - loss: 0.3905 - val_loss: 0.1245\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 935us/step - loss: 0.3933 - val_loss: 0.1153\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 904us/step - loss: 0.3927 - val_loss: 0.1152\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 918us/step - loss: 0.3887 - val_loss: 0.1156\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 852us/step - loss: 0.3879 - val_loss: 0.1157\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 828us/step - loss: 0.3855 - val_loss: 0.1149\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 844us/step - loss: 0.3883 - val_loss: 0.1153\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 857us/step - loss: 0.3857 - val_loss: 0.1159\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 878us/step - loss: 0.3859 - val_loss: 0.1159\n",
      "Epoch 11: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 0.1649 - val_loss: 0.5787\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1561 - val_loss: 0.5747\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 999us/step - loss: 0.1476 - val_loss: 0.5673\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 930us/step - loss: 0.1425 - val_loss: 0.5563\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 887us/step - loss: 0.1383 - val_loss: 0.5457\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 948us/step - loss: 0.1350 - val_loss: 0.5395\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1328 - val_loss: 0.5357\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 956us/step - loss: 0.1309 - val_loss: 0.5233\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 905us/step - loss: 0.1280 - val_loss: 0.5100\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 834us/step - loss: 0.1265 - val_loss: 0.5003\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 901us/step - loss: 0.1242 - val_loss: 0.4913\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1210 - val_loss: 0.4733\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1183 - val_loss: 0.4616\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1173 - val_loss: 0.4512\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1146 - val_loss: 0.4355\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1110 - val_loss: 0.4208\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 0s 872us/step - loss: 0.1086 - val_loss: 0.4046\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 0s 931us/step - loss: 0.1059 - val_loss: 0.3937\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.1028 - val_loss: 0.3746\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 0s 970us/step - loss: 0.1004 - val_loss: 0.3644\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 0s 925us/step - loss: 0.0985 - val_loss: 0.3543\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.0962 - val_loss: 0.3430\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 0s 978us/step - loss: 0.0948 - val_loss: 0.3371\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 0s 986us/step - loss: 0.0928 - val_loss: 0.3304\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 0s 978us/step - loss: 0.0922 - val_loss: 0.3321\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.3277\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 0s 848us/step - loss: 0.0898 - val_loss: 0.3231\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 0s 840us/step - loss: 0.0892 - val_loss: 0.3215\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.0879 - val_loss: 0.3175\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 0s 987us/step - loss: 0.0871 - val_loss: 0.3137\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 0s 965us/step - loss: 0.0872 - val_loss: 0.3153\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.0866 - val_loss: 0.3152\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 0s 988us/step - loss: 0.0857 - val_loss: 0.3131\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 0s 965us/step - loss: 0.0854 - val_loss: 0.3129\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 0s 981us/step - loss: 0.0852 - val_loss: 0.3141\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.0842 - val_loss: 0.3170\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 0s 962us/step - loss: 0.0844 - val_loss: 0.3127\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 0s 917us/step - loss: 0.0838 - val_loss: 0.3131\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 0s 949us/step - loss: 0.0831 - val_loss: 0.3149\n",
      "Epoch 39: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 1s 1ms/step - loss: 0.3374 - val_loss: 0.0613\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 0s 894us/step - loss: 0.3254 - val_loss: 0.0630\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 0s 875us/step - loss: 0.3184 - val_loss: 0.0612\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 0s 949us/step - loss: 0.3115 - val_loss: 0.0637\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 0s 896us/step - loss: 0.3084 - val_loss: 0.0612\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 0s 930us/step - loss: 0.3048 - val_loss: 0.0620\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 0s 886us/step - loss: 0.3048 - val_loss: 0.0623\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 0s 861us/step - loss: 0.3021 - val_loss: 0.0606\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 0s 839us/step - loss: 0.3009 - val_loss: 0.0607\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.0603\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.0615\n",
      "Epoch 11: early stopping\n",
      "461/461 [==============================] - 0s 618us/step\n",
      "Acc: 96.653% \n",
      "\n",
      "Precision: 0.682 \n",
      "\n",
      "F1score: 0.803 \n",
      "\n",
      "Recall: 0.977 \n",
      "\n",
      "AUC_ROC: 0.971 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"\\nRunning round: {i}\\n\")\n",
    "    pool.servers.map(copy_model_to_clients_ae, pool.clients)\n",
    "    pool.clients.map(train_ae)\n",
    "    pool.aggregators.map(weights_collector_ae, pool.clients)\n",
    "    pool.aggregators.map(aggregate_ae)\n",
    "    pool.aggregators.map(set_aggregated_weights_ae, pool.servers)\n",
    "output_model = pool.servers._models[\"autoencoder_server\"][\"model\"]\n",
    "output_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': '96.653%',\n",
       " 'Precision': '0.682',\n",
       " 'F1': '0.803',\n",
       " 'Recall': '0.977',\n",
       " 'AUC_ROC': '0.971'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_model.result_metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_experiments_results(\n",
    "    \"autoencoder\",\n",
    "    output_model,\n",
    "    \"test_autoencoder_notebook\",\n",
    "    model_params,\n",
    "    \"shuttle.mat\",\n",
    "    5,\n",
    "    3,\n",
    "    0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1bb7960fd30cfaed40cb92889ad99bb2687045b6865895d20dad709adf6b60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
