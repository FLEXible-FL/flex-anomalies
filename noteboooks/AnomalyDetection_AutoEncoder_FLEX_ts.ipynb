{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Auto Encoder with Flex for time series Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.utils import AutoEncoder\n",
    "from flexanomalies.utils.load_data import split_data, federate_data\n",
    "from flexanomalies.datasets.preprocessing_utils import (\n",
    "    create_windows,\n",
    "    encode_and_bind,\n",
    "    scaling,\n",
    "    impute_lost_values,\n",
    ")\n",
    "from flexanomalies.utils.metrics import print_metrics\n",
    "from flexanomalies.utils.process_scores import (\n",
    "    process_scores_with_percentile,\n",
    "    process_scores_with_threshold,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from flexanomalies.pool.primitives_deepmodel import (\n",
    "    build_server_model_ae,\n",
    "    copy_model_to_clients_ae,\n",
    "    train_ae,\n",
    "    set_aggregated_weights_ae,\n",
    "    weights_collector_ae,\n",
    "    evaluate_global_model,\n",
    "    evaluate_global_model_clients,\n",
    "    threshold_collector_ae,\n",
    ")\n",
    "from flexanomalies.pool.aggregators_favg import aggregate_ae\n",
    "from flexanomalies.pool.aggregators_stats import aggregate_stats_mean\n",
    "from flexanomalies.utils.save_results import save_experiments_results\n",
    "from flex.pool import FlexPool\n",
    "from flexanomalies.utils.metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, preprocessing and define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../flex-anomalies/flexanomalies/datasets/data/corrected.gz\"\n",
    "split_test = 0.3\n",
    "\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# process labels\n",
    "df.loc[df[41] != \"normal.\", 41] = 1\n",
    "df.loc[df[41] == \"normal.\", 41] = 0\n",
    "labels = df[41]\n",
    "df = df.drop([41], axis=1)\n",
    "\n",
    "features_to_encode = [1, 2, 3]\n",
    "df = df.drop(features_to_encode, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"epochs\": 50,\n",
    "    \"input_dim\": df.shape[1],\n",
    "    \"batch_size\": 32,\n",
    "    \"neurons\": [16, 8, 16],\n",
    "    \"hidden_act\": [\"relu\", \"relu\", \"relu\"],\n",
    "    \"preprocess\":False,\n",
    "    \"w_size\": 30,\n",
    "    \"n_pred\": 10,\n",
    "    \"contamination\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing (time series) and definition of the sliding window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaling(np.array(df.iloc[:, :].astype(float)))\n",
    "y = np.array(labels)\n",
    "X_train, X_test, l_train, l_test = split_data(X, y, split_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(w_size, n_pred, X_train, X_test, l_train, l_test):\n",
    "    X_train_windows = []\n",
    "    y_train_windows = []\n",
    "    X_test_windows = []\n",
    "    y_test_windows = []\n",
    "\n",
    "    for i in range(0, len(X_train), n_pred):\n",
    "        temp_xtrain = X_train[i : w_size + i, :]\n",
    "        temp_ytrain = l_train[i : w_size + i]\n",
    "        if len(temp_xtrain) < w_size or len(temp_ytrain) < n_pred:\n",
    "            break\n",
    "        X_train_windows.append(temp_xtrain)\n",
    "\n",
    "        y_train_windows.append(temp_ytrain)\n",
    "\n",
    "    for i in range(0, len(X_test), n_pred):\n",
    "\n",
    "        temp_xtest = X_test[i : w_size + i, :]\n",
    "        temp_ytest = l_test[i : w_size + i]\n",
    "        if len(temp_xtest) < w_size or len(temp_ytest) < n_pred:\n",
    "            break\n",
    "\n",
    "        X_test_windows.append(temp_xtest)\n",
    "\n",
    "        y_test_windows.append(temp_ytest)\n",
    "\n",
    "    return (\n",
    "        np.array(X_train_windows),\n",
    "        np.array(y_train_windows),\n",
    "        np.array(X_test_windows),\n",
    "        np.array(y_test_windows),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train_windows,\n",
    "    y_train_windows,\n",
    "    X_test_windows,\n",
    "    y_test_windows,\n",
    "    \n",
    ") = create_windows(model_params[\"w_size\"], model_params[\"n_pred\"], X_train, X_test,l_train, l_test)\n",
    "\n",
    "print(\"X_train shape == {}.\".format(np.array(X_train_windows).shape))\n",
    "print(\"y_train shape == {}.\".format(np.array(y_train_windows).shape))\n",
    "print(\"X_test shape == {}.\".format(np.array(X_test_windows).shape))\n",
    "print(\"y_test shape == {}.\".format(np.array(y_test_windows).shape))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(**model_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the federated architecture\n",
    "\n",
    "Once the data  is loaded and preprocessed, we have to federate it. For this we use the FLEX library. There are two ways to federate the data, using an IID distribution or a non IID distribution. For the IID distribution we can use the Ã¬id_distribution \n",
    "\n",
    "function of FedDataDistribution. If we use a non-IID distribution, it is necessary to use a custom configuration, such as the one used in the federate_data function. For more information, go to the FLEX library workbooks, and take a look at the \n",
    "\n",
    "Federate Data with FLEXible notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dataset = federate_data(5, X_train_windows,X_train_windows)\n",
    "pool = FlexPool.client_server_pool(\n",
    "    fed_dataset=flex_dataset,\n",
    "    server_id=\"autoencoder_server\",\n",
    "    init_func=build_server_model_ae,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run the federated learning experiment and Evaluate\n",
    "Now, we can run the federated experiment for multiple rounds using the decorators. \n",
    "\n",
    "Once the model is trained, we need to evaluate it at the server level and at client level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"\\nRunning round: {i}\\n\")\n",
    "    pool.servers.map(copy_model_to_clients_ae, pool.clients)\n",
    "    pool.clients.map(train_ae)\n",
    "    pool.aggregators.map(weights_collector_ae, pool.clients)\n",
    "    pool.aggregators.map(aggregate_ae)\n",
    "    pool.aggregators.map(set_aggregated_weights_ae, pool.servers)\n",
    "output_model = pool.servers._models[\"autoencoder_server\"][\"model\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_global_model(output_model, X_test_windows, X_test_windows, y_test_windows.flatten().astype(\"int\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating at client level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate it at the client level, the function evaluate_global_model_clients is used, which uses the test set in each of the clients, predicts the corresponding values, evaluates and an anomaly threshold is obtained.\n",
    "\n",
    "The threshold_collector_ae function obtains the threshold for each of the clients and the aggregate_stats_mean function performs the aggregation of the thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pool.clients.map(evaluate_global_model_clients)\n",
    "thresholds = pool.clients.map(threshold_collector_ae)\n",
    "aggregate_stats_mean(thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, the threshold is used to evaluate the model at the server level and perform labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_global_model(\n",
    "    output_model,\n",
    "    X_test_windows,\n",
    "    X_test_windows,\n",
    "    y_test_windows.flatten().astype(\"int\"),\n",
    "    threshold=aggregate_stats_mean(thresholds),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1bb7960fd30cfaed40cb92889ad99bb2687045b6865895d20dad709adf6b60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
