{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.utils import AutoEncoder\n",
    "from flexanomalies.utils.load_data import split_data, federate_data\n",
    "from flexanomalies.datasets.preprocessing_utils import (\n",
    "    create_windows,\n",
    "    encode_and_bind,\n",
    "    scaling,\n",
    "    impute_lost_values,\n",
    ")\n",
    "from flexanomalies.utils.metrics import print_metrics\n",
    "from flexanomalies.utils.process_scores import (\n",
    "    process_scores_with_percentile,\n",
    "    process_scores_with_threshold,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from flexanomalies.pool.primitives_deepmodel import (\n",
    "    build_server_model_ae,\n",
    "    copy_model_to_clients_ae,\n",
    "    train_ae,\n",
    "    set_aggregated_weights_ae,\n",
    "    weights_collector_ae,\n",
    "    evaluate_global_model,\n",
    "    evaluate_global_model_clients,\n",
    "    threshold_collector_ae,\n",
    ")\n",
    "from flexanomalies.pool.aggregators_favg import aggregate_ae\n",
    "from flexanomalies.utils.save_results import save_experiments_results\n",
    "from flex.pool import FlexPool\n",
    "from flexanomalies.utils.metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../flex-anomalies/flexanomalies/datasets/data/corrected.gz\"\n",
    "split_test = 0.3\n",
    "\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# process labels\n",
    "df.loc[df[41] != \"normal.\", 41] = 1\n",
    "df.loc[df[41] == \"normal.\", 41] = 0\n",
    "labels = df[41]\n",
    "df = df.drop([41], axis=1)\n",
    "\n",
    "features_to_encode = [1, 2, 3]\n",
    "df = df.drop(features_to_encode, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"epochs\": 50,\n",
    "    \"input_dim\": df.shape[1],\n",
    "    \"batch_size\": 32,\n",
    "    \"neurons\": [16, 8, 16],\n",
    "    \"hidden_act\": [\"relu\", \"relu\", \"relu\"],\n",
    "    \"preprocess\":False,\n",
    "    \"w_size\": 30,\n",
    "    \"n_pred\": 10,\n",
    "    \"contamination\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaling(np.array(df.iloc[:, :].astype(float)))\n",
    "y = np.array(labels)\n",
    "X_train, X_test, l_train, l_test = split_data(X, y, split_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(w_size, n_pred, X_train, X_test, l_train, l_test):\n",
    "    X_train_windows = []\n",
    "    y_train_windows = []\n",
    "    X_test_windows = []\n",
    "    y_test_windows = []\n",
    "\n",
    "    for i in range(0, len(X_train), n_pred):\n",
    "        temp_xtrain = X_train[i : w_size + i, :]\n",
    "        temp_ytrain = l_train[i : w_size + i]\n",
    "        if len(temp_xtrain) < w_size or len(temp_ytrain) < n_pred:\n",
    "            break\n",
    "        X_train_windows.append(temp_xtrain)\n",
    "\n",
    "        y_train_windows.append(temp_ytrain)\n",
    "\n",
    "    for i in range(0, len(X_test), n_pred):\n",
    "\n",
    "        temp_xtest = X_test[i : w_size + i, :]\n",
    "        temp_ytest = l_test[i : w_size + i]\n",
    "        if len(temp_xtest) < w_size or len(temp_ytest) < n_pred:\n",
    "            break\n",
    "\n",
    "        X_test_windows.append(temp_xtest)\n",
    "\n",
    "        y_test_windows.append(temp_ytest)\n",
    "\n",
    "    return (\n",
    "        np.array(X_train_windows),\n",
    "        np.array(y_train_windows),\n",
    "        np.array(X_test_windows),\n",
    "        np.array(y_test_windows),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape == (21770, 30, 38).\n",
      "y_train shape == (21770, 30).\n",
      "X_test shape == (9328, 30, 38).\n",
      "y_test shape == (9328, 30).\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    X_train_windows,\n",
    "    y_train_windows,\n",
    "    X_test_windows,\n",
    "    y_test_windows,\n",
    "    \n",
    ") = create_windows(model_params[\"w_size\"], model_params[\"n_pred\"], X_train, X_test,l_train, l_test)\n",
    "\n",
    "print(\"X_train shape == {}.\".format(np.array(X_train_windows).shape))\n",
    "print(\"y_train shape == {}.\".format(np.array(y_train_windows).shape))\n",
    "print(\"X_test shape == {}.\".format(np.array(X_test_windows).shape))\n",
    "print(\"y_test shape == {}.\".format(np.array(y_test_windows).shape))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(**model_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dataset = federate_data(5, X_train_windows,X_train_windows)\n",
    "pool = FlexPool.client_server_pool(\n",
    "    fed_dataset=flex_dataset,\n",
    "    server_id=\"autoencoder_server\",\n",
    "    init_func=build_server_model_ae,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running round: 0\n",
      "\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:04         2241\n",
      "variables.h5                                   2024-01-11 12:32:04        22544\n",
      "metadata.json                                  2024-01-11 12:32:04           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:04         2241\n",
      "variables.h5                                   2024-01-11 12:32:04        22544\n",
      "metadata.json                                  2024-01-11 12:32:04           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:04         2241\n",
      "variables.h5                                   2024-01-11 12:32:04        22544\n",
      "metadata.json                                  2024-01-11 12:32:04           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:04         2241\n",
      "variables.h5                                   2024-01-11 12:32:04        22544\n",
      "metadata.json                                  2024-01-11 12:32:04           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:05         2241\n",
      "variables.h5                                   2024-01-11 12:32:05        22544\n",
      "metadata.json                                  2024-01-11 12:32:05           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:04         2241\n",
      "variables.h5                                   2024-01-11 12:32:04        22544\n",
      "metadata.json                                  2024-01-11 12:32:04           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:05         2241\n",
      "variables.h5                                   2024-01-11 12:32:05        22544\n",
      "metadata.json                                  2024-01-11 12:32:05           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:04         2241\n",
      "variables.h5                                   2024-01-11 12:32:04        22544\n",
      "metadata.json                                  2024-01-11 12:32:04           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:05         2241\n",
      "variables.h5                                   2024-01-11 12:32:05        22544\n",
      "metadata.json                                  2024-01-11 12:32:05           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:04         2241\n",
      "variables.h5                                   2024-01-11 12:32:04        22544\n",
      "metadata.json                                  2024-01-11 12:32:04           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.9277 - val_loss: 0.8710\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.6785 - val_loss: 0.6954\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5602 - val_loss: 0.6105\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4904 - val_loss: 0.5589\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4431 - val_loss: 0.5181\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.4810\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3669 - val_loss: 0.4418\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3343 - val_loss: 0.4013\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3068 - val_loss: 0.3643\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2832 - val_loss: 0.3323\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2622 - val_loss: 0.2970\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2435 - val_loss: 0.2718\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2265 - val_loss: 0.2470\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2130 - val_loss: 0.2282\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2026 - val_loss: 0.2144\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1928 - val_loss: 0.2025\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1857 - val_loss: 0.1923\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1778 - val_loss: 0.1826\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1709 - val_loss: 0.1739\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1653 - val_loss: 0.1663\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1593 - val_loss: 0.1610\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1534\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1497 - val_loss: 0.1484\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1475 - val_loss: 0.1444\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1434 - val_loss: 0.1397\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1393 - val_loss: 0.1373\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1364 - val_loss: 0.1339\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1337 - val_loss: 0.1329\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1319 - val_loss: 0.1299\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1286 - val_loss: 0.1254\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1266 - val_loss: 0.1242\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.1212\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1218 - val_loss: 0.1183\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1194 - val_loss: 0.1172\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1168 - val_loss: 0.1142\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1130\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1136 - val_loss: 0.1113\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1119 - val_loss: 0.1099\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.1094\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1099 - val_loss: 0.1081\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1081\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1072 - val_loss: 0.1060\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1053 - val_loss: 0.1046\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.1032\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 0.1020\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.1026\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.1010\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0999 - val_loss: 0.1009\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1005 - val_loss: 0.0996\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0987 - val_loss: 0.0993\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.8400 - val_loss: 0.9743\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.7997\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4930 - val_loss: 0.7113\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.6594\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.6164\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3636 - val_loss: 0.5722\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.5250\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.4797\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2751 - val_loss: 0.4258\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2429 - val_loss: 0.3657\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2127 - val_loss: 0.3094\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1850 - val_loss: 0.2622\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1599 - val_loss: 0.2275\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1434 - val_loss: 0.2110\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1329 - val_loss: 0.1984\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1264 - val_loss: 0.1915\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1202 - val_loss: 0.1848\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1145 - val_loss: 0.1755\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1077 - val_loss: 0.1695\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1029 - val_loss: 0.1649\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.1618\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0989 - val_loss: 0.1617\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.1601\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.1581\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0934 - val_loss: 0.1522\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.1500\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0888 - val_loss: 0.1493\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.1486\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.1487\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.1462\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.1458\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.1490\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.1528\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.1465\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.1437\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.1420\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.1407\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.1407\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.1407\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.1419\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.1411\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.1404\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.1397\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.1362\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.1360\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.1342\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.1344\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.1323\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.1340\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.1314\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.8291 - val_loss: 0.5796\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5655 - val_loss: 0.3900\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4421 - val_loss: 0.3175\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.2776\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3434 - val_loss: 0.2365\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3126 - val_loss: 0.2148\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.1975\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2756 - val_loss: 0.1858\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2604 - val_loss: 0.1760\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2438 - val_loss: 0.1663\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2289 - val_loss: 0.1599\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2102 - val_loss: 0.1529\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1924 - val_loss: 0.1456\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1744 - val_loss: 0.1379\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1564 - val_loss: 0.1302\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1419 - val_loss: 0.1229\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1312 - val_loss: 0.1183\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1225 - val_loss: 0.1121\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.1080\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1125 - val_loss: 0.1036\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1096 - val_loss: 0.1017\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1059 - val_loss: 0.0985\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1037 - val_loss: 0.0958\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1015 - val_loss: 0.0932\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1000 - val_loss: 0.0909\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 0.0887\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0970 - val_loss: 0.0869\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.0858\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0957 - val_loss: 0.0834\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.0819\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.0806\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.0789\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0787\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.0772\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.0754\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.0743\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0730\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0842 - val_loss: 0.0714\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0829 - val_loss: 0.0705\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0683\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0666\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0653\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0829 - val_loss: 0.0671\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0625\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0614\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0603\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0592\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0584\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0574\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0569\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.7978 - val_loss: 0.7485\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5491 - val_loss: 0.5802\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4361 - val_loss: 0.4993\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4473\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3959\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3508\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2773 - val_loss: 0.3153\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2504 - val_loss: 0.2831\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2293 - val_loss: 0.2562\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2087 - val_loss: 0.2281\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1909 - val_loss: 0.2048\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1775 - val_loss: 0.1878\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1655 - val_loss: 0.1737\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.1624\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1491 - val_loss: 0.1533\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1432 - val_loss: 0.1476\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1384 - val_loss: 0.1423\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1339 - val_loss: 0.1373\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1302 - val_loss: 0.1332\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1266 - val_loss: 0.1312\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1232 - val_loss: 0.1286\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1196 - val_loss: 0.1262\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1244\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1140 - val_loss: 0.1213\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.1178\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1077 - val_loss: 0.1159\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.1145\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1022 - val_loss: 0.1123\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0999 - val_loss: 0.1108\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0980 - val_loss: 0.1097\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0962 - val_loss: 0.1058\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.1064\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.1013\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0905 - val_loss: 0.1016\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.1019\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.0986\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0947\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.0942\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.0928\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0924\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0883\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0860\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0899\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0843\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0837\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0818\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0805\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0797\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0793\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.9751 - val_loss: 0.6288\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.7122 - val_loss: 0.4522\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5613 - val_loss: 0.3871\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.3601\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3424\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 0.3265\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2458 - val_loss: 0.3119\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2180 - val_loss: 0.2998\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2018 - val_loss: 0.2912\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1908 - val_loss: 0.2822\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1832 - val_loss: 0.2739\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1789 - val_loss: 0.2666\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1710 - val_loss: 0.2611\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1696 - val_loss: 0.2570\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1630 - val_loss: 0.2533\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1601 - val_loss: 0.2501\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1594 - val_loss: 0.2469\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1539 - val_loss: 0.2438\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1496 - val_loss: 0.2406\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1463 - val_loss: 0.2381\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1444 - val_loss: 0.2363\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1527 - val_loss: 0.2340\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1406 - val_loss: 0.2314\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1369 - val_loss: 0.2296\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 0.2275\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1345 - val_loss: 0.2258\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.2239\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1352 - val_loss: 0.2216\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1368 - val_loss: 0.2193\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1264 - val_loss: 0.2172\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1242 - val_loss: 0.2154\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1214 - val_loss: 0.2125\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1193 - val_loss: 0.2094\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.2073\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1160 - val_loss: 0.2049\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.2023\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1127 - val_loss: 0.1990\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1114 - val_loss: 0.1957\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1416 - val_loss: 0.1933\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1136 - val_loss: 0.1894\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1068 - val_loss: 0.1862\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1039 - val_loss: 0.1837\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.1807\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.1780\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.1755\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.1736\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.1711\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.1703\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.1677\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 0.1662\n",
      "\n",
      "Running round: 1\n",
      "\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:51         2241\n",
      "variables.h5                                   2024-01-11 12:32:51        22544\n",
      "metadata.json                                  2024-01-11 12:32:51           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:50         2241\n",
      "variables.h5                                   2024-01-11 12:32:50        22544\n",
      "metadata.json                                  2024-01-11 12:32:50           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:51         2241\n",
      "variables.h5                                   2024-01-11 12:32:51        22544\n",
      "metadata.json                                  2024-01-11 12:32:51           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:50         2241\n",
      "variables.h5                                   2024-01-11 12:32:50        22544\n",
      "metadata.json                                  2024-01-11 12:32:50           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:51         2241\n",
      "variables.h5                                   2024-01-11 12:32:51        22544\n",
      "metadata.json                                  2024-01-11 12:32:51           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:50         2241\n",
      "variables.h5                                   2024-01-11 12:32:50        22544\n",
      "metadata.json                                  2024-01-11 12:32:50           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:51         2241\n",
      "variables.h5                                   2024-01-11 12:32:51        22544\n",
      "metadata.json                                  2024-01-11 12:32:51           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:50         2241\n",
      "variables.h5                                   2024-01-11 12:32:50        22544\n",
      "metadata.json                                  2024-01-11 12:32:50           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:52         2241\n",
      "variables.h5                                   2024-01-11 12:32:52        22544\n",
      "metadata.json                                  2024-01-11 12:32:52           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:32:52         2241\n",
      "variables.h5                                   2024-01-11 12:32:52        22544\n",
      "metadata.json                                  2024-01-11 12:32:52           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.4481\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3195 - val_loss: 0.4066\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2866 - val_loss: 0.3688\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2555 - val_loss: 0.3280\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2275 - val_loss: 0.2841\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2040 - val_loss: 0.2515\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1825 - val_loss: 0.2221\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1658 - val_loss: 0.1975\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1506 - val_loss: 0.1758\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1371 - val_loss: 0.1615\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1271 - val_loss: 0.1436\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.1332\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.1234\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1047 - val_loss: 0.1175\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.1125\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0982 - val_loss: 0.1112\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.1092\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0951 - val_loss: 0.1067\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0939 - val_loss: 0.1051\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.1039\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0925 - val_loss: 0.1034\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.1015\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0911 - val_loss: 0.1014\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.1018\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.1014\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.0995\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.0996\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.1007\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.1021\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0897 - val_loss: 0.1015\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.0990\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.1000\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.0986\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0980\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0983\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0965\n",
      "Epoch 36: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.3664 - val_loss: 0.2218\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3143 - val_loss: 0.1985\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2777 - val_loss: 0.1789\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2393 - val_loss: 0.1652\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1864 - val_loss: 0.1472\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1413 - val_loss: 0.1335\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1253\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.1220\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.1148\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.1120\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0813 - val_loss: 0.1126\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.1101\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.1072\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.1056\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.1050\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.1050\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.1029\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.1020\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0987\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0973\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0960\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0959\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0934\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.1082\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0915\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0895\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0887\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0880\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0866\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0866\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0865\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0851\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0847\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0864\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0872\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0843\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0843\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0834\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0831\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0831\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0823\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0827\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0820\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0622 - val_loss: 0.0840\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0689 - val_loss: 0.0821\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0832\n",
      "Epoch 46: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.2498 - val_loss: 0.1689\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2100 - val_loss: 0.1525\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1924 - val_loss: 0.1429\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1746 - val_loss: 0.1387\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1595 - val_loss: 0.1309\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1478 - val_loss: 0.1323\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1301\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1261 - val_loss: 0.1292\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1293\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1140 - val_loss: 0.1351\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1078 - val_loss: 0.1271\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1037 - val_loss: 0.1207\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.1196\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0949 - val_loss: 0.1171\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.1148\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 0.1126\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.1099\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.1075\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.1068\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.1029\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.1011\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.1012\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.1012\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0965\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0942\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0888\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0869\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0836\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0807\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0790\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0765\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0767\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0791\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0712\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0712\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0682\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0661\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0648\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0630\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0614\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0627\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0601\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.0591\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0590\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0582\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0579\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0622\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0566\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0582\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0557\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.2166 - val_loss: 0.3879\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1783 - val_loss: 0.3510\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1584 - val_loss: 0.3093\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1459 - val_loss: 0.2825\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1364 - val_loss: 0.2634\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1297 - val_loss: 0.2504\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1246 - val_loss: 0.2294\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1206 - val_loss: 0.2128\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1157 - val_loss: 0.2124\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1934\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1082 - val_loss: 0.1882\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1047 - val_loss: 0.1791\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1011 - val_loss: 0.1690\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.1658\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.1578\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.1537\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.1461\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.1378\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.1366\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.1305\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.1245\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.1235\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0808 - val_loss: 0.1201\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.1123\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.1111\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.1027\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.1015\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0987\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.1019\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0936\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0700 - val_loss: 0.0911\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0885\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0863\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0849\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0843\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0821\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0815\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0867\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0795\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0804\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0790\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0777\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0803\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0781\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0771\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0785\n",
      "Epoch 46: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.4331 - val_loss: 0.1526\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.1429\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2952 - val_loss: 0.1371\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2151 - val_loss: 0.1337\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1599 - val_loss: 0.1299\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1306 - val_loss: 0.1277\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1124 - val_loss: 0.1251\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.1238\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0923 - val_loss: 0.1232\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.1246\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0874 - val_loss: 0.1212\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.1200\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.1184\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.1177\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.1174\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.1160\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.1152\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.1150\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.1145\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.1138\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.1137\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.1126\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.1124\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.1118\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.1116\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.1110\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.1122\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.1107\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.1099\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.1096\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.1094\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.1111\n",
      "Epoch 32: early stopping\n",
      "\n",
      "Running round: 2\n",
      "\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:33:31         2241\n",
      "variables.h5                                   2024-01-11 12:33:31        22544\n",
      "metadata.json                                  2024-01-11 12:33:31           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:33:30         2241\n",
      "variables.h5                                   2024-01-11 12:33:30        22544\n",
      "metadata.json                                  2024-01-11 12:33:30           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:33:31         2241\n",
      "variables.h5                                   2024-01-11 12:33:31        22544\n",
      "metadata.json                                  2024-01-11 12:33:31           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:33:30         2241\n",
      "variables.h5                                   2024-01-11 12:33:30        22544\n",
      "metadata.json                                  2024-01-11 12:33:30           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:33:31         2241\n",
      "variables.h5                                   2024-01-11 12:33:31        22544\n",
      "metadata.json                                  2024-01-11 12:33:31           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:33:30         2241\n",
      "variables.h5                                   2024-01-11 12:33:30        22544\n",
      "metadata.json                                  2024-01-11 12:33:30           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:33:31         2241\n",
      "variables.h5                                   2024-01-11 12:33:31        22544\n",
      "metadata.json                                  2024-01-11 12:33:31           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:33:30         2241\n",
      "variables.h5                                   2024-01-11 12:33:30        22544\n",
      "metadata.json                                  2024-01-11 12:33:30           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:33:31         2241\n",
      "variables.h5                                   2024-01-11 12:33:31        22544\n",
      "metadata.json                                  2024-01-11 12:33:31           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-01-11 12:33:30         2241\n",
      "variables.h5                                   2024-01-11 12:33:30        22544\n",
      "metadata.json                                  2024-01-11 12:33:30           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.2988 - val_loss: 0.1378\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2526 - val_loss: 0.1206\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2080 - val_loss: 0.1136\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1731 - val_loss: 0.1050\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1472 - val_loss: 0.0995\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1290 - val_loss: 0.0960\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1186 - val_loss: 0.0940\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1105 - val_loss: 0.0935\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1044 - val_loss: 0.0907\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.0896\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0976 - val_loss: 0.0901\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0959 - val_loss: 0.0894\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0949 - val_loss: 0.0880\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0943 - val_loss: 0.0879\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0950 - val_loss: 0.0868\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0929 - val_loss: 0.0867\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.0871\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.0854\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0919 - val_loss: 0.0847\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0862\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0907 - val_loss: 0.0857\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0913 - val_loss: 0.0850\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0905 - val_loss: 0.0855\n",
      "Epoch 23: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.2458 - val_loss: 0.2886\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2165 - val_loss: 0.2579\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1944 - val_loss: 0.2350\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1703 - val_loss: 0.2248\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.1721\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1257 - val_loss: 0.1362\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1063 - val_loss: 0.1085\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0937 - val_loss: 0.0941\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0889\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0835\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.0725\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.1014\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0627\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0623\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0623\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0627\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0626\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0630\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0650\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.0607\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0597\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0612\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0668 - val_loss: 0.0636\n",
      "Epoch 23: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.1438 - val_loss: 0.1006\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1136 - val_loss: 0.0987\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0934 - val_loss: 0.0977\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.0906\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0892\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0823\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0812\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0764\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0723\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0709\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0656\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0652\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0634\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0665\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0696\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0597\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0638\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0601\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0613\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0485 - val_loss: 0.0580\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0473 - val_loss: 0.0580\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0575\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0598\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0577\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0588\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0585\n",
      "Epoch 26: early stopping\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.1759 - val_loss: 0.1388\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1389\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1367 - val_loss: 0.1370\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1222 - val_loss: 0.1363\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1152 - val_loss: 0.1341\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1081 - val_loss: 0.1305\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1035 - val_loss: 0.1310\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0991 - val_loss: 0.1292\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0960 - val_loss: 0.1297\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.1261\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.1242\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.1229\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.1187\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.1163\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.1144\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.1135\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.1087\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.1071\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.1043\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.1021\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.1015\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0989\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0973\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0965\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0940\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0942\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0930\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0912\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0936\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0903\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0887\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0880\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0874\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0864\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0853\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0861\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0846\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0839\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0827\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0836\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0813\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0812\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0812\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0813\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0815\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0806\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0801\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0776\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0770\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0773\n",
      "Training model at client.\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.1668\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2724 - val_loss: 0.1691\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2009 - val_loss: 0.1737\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.1335 - val_loss: 0.1718\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1055 - val_loss: 0.1694\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.1636\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.1613\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.1568\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.1564\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.1505\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.1540\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.1467\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.1446\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.1451\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.1432\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.1422\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.1437\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.1464\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.1417\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.1404\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.1406\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.1408\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.1401\n",
      "Epoch 23: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"\\nRunning round: {i}\\n\")\n",
    "    pool.servers.map(copy_model_to_clients_ae, pool.clients)\n",
    "    pool.clients.map(train_ae)\n",
    "    pool.aggregators.map(weights_collector_ae, pool.clients)\n",
    "    pool.aggregators.map(aggregate_ae)\n",
    "    pool.aggregators.map(set_aggregated_weights_ae, pool.servers)\n",
    "output_model = pool.servers._models[\"autoencoder_server\"][\"model\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 0s 724us/step\n",
      "Acc: 72.934% \n",
      "\n",
      "Precision: 0.900 \n",
      "\n",
      "F1score: 0.817 \n",
      "\n",
      "Recall: 0.748 \n",
      "\n",
      "AUC_ROC: 0.700 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_global_model(output_model, X_test_windows, X_test_windows, y_test_windows.flatten().astype(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flex_dataset1 = federate_data(5, X_test_windows, X_test_windows)\n",
    "pool._data = flex_dataset1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_global_model_clients(client_flex_model, client_data, *args, **kwargs):\n",
    "\n",
    "#     X_test, y_test = client_data.to_numpy()\n",
    "#     p = client_flex_model[\"model\"].predict(X_test, y_test)\n",
    "#     d_scores = np.mean((X_test - p), axis=2)\n",
    "#     threshold = process_scores_with_percentile(d_scores, 0.1)\n",
    "#     client_flex_model[\"threshold\"] = threshold\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.pool.aggregators_stats import aggregate_stats_mean\n",
    "\n",
    "pool.clients.map(evaluate_global_model_clients)\n",
    "thresholds = pool.clients.map(threshold_collector_ae)\n",
    "aggregate_stats_mean(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 0s 638us/step\n",
      "Acc: 78.222% \n",
      "\n",
      "Precision: 0.905 \n",
      "\n",
      "F1score: 0.858 \n",
      "\n",
      "Recall: 0.816 \n",
      "\n",
      "AUC_ROC: 0.729 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_global_model(\n",
    "    output_model,\n",
    "    X_test_windows,\n",
    "    X_test_windows,\n",
    "    y_test_windows.flatten().astype(\"int\"),\n",
    "    threshold=aggregate_stats_mean(thresholds),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1bb7960fd30cfaed40cb92889ad99bb2687045b6865895d20dad709adf6b60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
